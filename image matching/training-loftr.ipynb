{"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/gdrive/imc/input')"],"metadata":{"id":"BXnmxT6Ujhf9"},"id":"BXnmxT6Ujhf9","execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"id":"ddf3e0d8","metadata":{"execution":{"iopub.execute_input":"2022-04-17T18:14:35.976810Z","iopub.status.busy":"2022-04-17T18:14:35.976205Z","iopub.status.idle":"2022-04-17T18:15:04.760874Z","shell.execute_reply":"2022-04-17T18:15:04.759915Z"},"papermill":{"duration":28.803739,"end_time":"2022-04-17T18:15:04.763371","exception":false,"start_time":"2022-04-17T18:14:35.959632","status":"completed"},"tags":[],"id":"ddf3e0d8","outputId":"4b38fbf3-7a72-44a1-e913-715f32531292"},"outputs":[{"name":"stdout","output_type":"stream","text":["Processing /kaggle/input/kornia-loftr/kornia-0.6.4-py2.py3-none-any.whl\r\n","Requirement already satisfied: packaging in /opt/conda/lib/python3.7/site-packages (from kornia==0.6.4) (21.3)\r\n","Requirement already satisfied: torch>=1.8.1 in /opt/conda/lib/python3.7/site-packages (from kornia==0.6.4) (1.9.1)\r\n","Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.7/site-packages (from torch>=1.8.1->kornia==0.6.4) (4.1.1)\r\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging->kornia==0.6.4) (3.0.7)\r\n","Installing collected packages: kornia\r\n","  Attempting uninstall: kornia\r\n","    Found existing installation: kornia 0.5.8\r\n","    Uninstalling kornia-0.5.8:\r\n","      Successfully uninstalled kornia-0.5.8\r\n","Successfully installed kornia-0.6.4\r\n","\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\r\n","\u001b[0mProcessing /kaggle/input/kornia-loftr/kornia_moons-0.1.9-py3-none-any.whl\r\n","Requirement already satisfied: matplotlib in /opt/conda/lib/python3.7/site-packages (from kornia-moons==0.1.9) (3.5.1)\r\n","Requirement already satisfied: opencv-python in /opt/conda/lib/python3.7/site-packages (from kornia-moons==0.1.9) (4.5.4.60)\r\n","Requirement already satisfied: torch in /opt/conda/lib/python3.7/site-packages (from kornia-moons==0.1.9) (1.9.1)\r\n","Requirement already satisfied: kornia in /opt/conda/lib/python3.7/site-packages (from kornia-moons==0.1.9) (0.6.4)\r\n","Requirement already satisfied: packaging in /opt/conda/lib/python3.7/site-packages (from kornia->kornia-moons==0.1.9) (21.3)\r\n","Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.7/site-packages (from torch->kornia-moons==0.1.9) (4.1.1)\r\n","Requirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.7/site-packages (from matplotlib->kornia-moons==0.1.9) (9.0.1)\r\n","Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.7/site-packages (from matplotlib->kornia-moons==0.1.9) (0.11.0)\r\n","Requirement already satisfied: pyparsing>=2.2.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib->kornia-moons==0.1.9) (3.0.7)\r\n","Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.7/site-packages (from matplotlib->kornia-moons==0.1.9) (2.8.2)\r\n","Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.7/site-packages (from matplotlib->kornia-moons==0.1.9) (1.21.5)\r\n","Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib->kornia-moons==0.1.9) (1.4.0)\r\n","Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.7/site-packages (from matplotlib->kornia-moons==0.1.9) (4.30.0)\r\n","Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.7/site-packages (from python-dateutil>=2.7->matplotlib->kornia-moons==0.1.9) (1.16.0)\r\n","Installing collected packages: kornia-moons\r\n","Successfully installed kornia-moons-0.1.9\r\n","\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\r\n","\u001b[0mProcessing /kaggle/input/loftrutils/einops-0.4.1-py3-none-any.whl\r\n","Installing collected packages: einops\r\n","Successfully installed einops-0.4.1\r\n","\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\r\n","\u001b[0m"]}],"source":["!pip install ../input/kornia-loftr/kornia-0.6.4-py2.py3-none-any.whl\n","!pip install ../input/kornia-loftr/kornia_moons-0.1.9-py3-none-any.whl\n","!pip install ../input/loftrutils/einops-0.4.1-py3-none-any.whl"]},{"cell_type":"code","execution_count":null,"id":"09fde0cd","metadata":{"execution":{"iopub.execute_input":"2022-04-17T18:15:04.803802Z","iopub.status.busy":"2022-04-17T18:15:04.803548Z","iopub.status.idle":"2022-04-17T18:15:04.807635Z","shell.execute_reply":"2022-04-17T18:15:04.806854Z"},"papermill":{"duration":0.026102,"end_time":"2022-04-17T18:15:04.809503","exception":false,"start_time":"2022-04-17T18:15:04.783401","status":"completed"},"tags":[],"id":"09fde0cd"},"outputs":[],"source":["import sys\n","sys.path.append('../input/loftrutils/LoFTR-master/LoFTR-master/')"]},{"cell_type":"code","execution_count":null,"id":"79345438","metadata":{"execution":{"iopub.execute_input":"2022-04-17T18:15:04.848328Z","iopub.status.busy":"2022-04-17T18:15:04.847672Z","iopub.status.idle":"2022-04-17T18:15:14.702639Z","shell.execute_reply":"2022-04-17T18:15:14.701726Z"},"papermill":{"duration":9.876682,"end_time":"2022-04-17T18:15:14.704826","exception":false,"start_time":"2022-04-17T18:15:04.828144","status":"completed"},"tags":[],"id":"79345438","outputId":"d0ed7057-43ef-4ffc-9d04-f9d0344ef580"},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting loguru\r\n","  Downloading loguru-0.6.0-py3-none-any.whl (58 kB)\r\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 KB\u001b[0m \u001b[31m488.8 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n","\u001b[?25hInstalling collected packages: loguru\r\n","Successfully installed loguru-0.6.0\r\n","\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\r\n","\u001b[0m"]}],"source":["!pip install loguru"]},{"cell_type":"code","execution_count":null,"id":"a5273178","metadata":{"execution":{"iopub.execute_input":"2022-04-17T18:15:14.743742Z","iopub.status.busy":"2022-04-17T18:15:14.743517Z","iopub.status.idle":"2022-04-17T18:15:22.377837Z","shell.execute_reply":"2022-04-17T18:15:22.376606Z"},"papermill":{"duration":7.65657,"end_time":"2022-04-17T18:15:22.380123","exception":false,"start_time":"2022-04-17T18:15:14.723553","status":"completed"},"tags":[],"id":"a5273178"},"outputs":[],"source":["from collections import defaultdict\n","import pprint\n","from loguru import logger\n","from pathlib import Path\n","import cv2\n","import torch\n","import numpy as np\n","import pytorch_lightning as pl\n","from matplotlib import pyplot as plt\n","import gc\n","from src.loftr import LoFTR\n","from src.loftr.utils.supervision import compute_supervision_coarse, compute_supervision_fine\n","from src.losses.loftr_loss import LoFTRLoss\n","from src.optimizers import build_optimizer, build_scheduler\n","from src.utils.metrics import (\n","    compute_symmetrical_epipolar_errors,\n","    compute_pose_errors,\n","    aggregate_metrics\n",")\n","from src.utils.plotting import make_matching_figures\n","from src.utils.comm import gather, all_gather\n","from src.utils.misc import lower_config, flattenList\n","from src.utils.profiler import PassThroughProfiler\n","\n","\n","class PL_LoFTR(pl.LightningModule):\n","    def __init__(self, config, pretrained_ckpt=None, profiler=None, dump_dir=None):\n","        \"\"\"\n","        TODO:\n","            - use the new version of PL logging API.\n","        \"\"\"\n","        super().__init__()\n","        # Misc\n","        self.config = config  # full config\n","        _config = lower_config(self.config)\n","        self.loftr_cfg = lower_config(_config['loftr'])\n","        self.profiler = profiler or PassThroughProfiler()\n","        self.n_vals_plot = 1 #max(config.TRAINER.N_VAL_PAIRS_TO_PLOT // config.TRAINER.WORLD_SIZE, 1)\n","\n","        # Matcher: LoFTR\n","        self.matcher = LoFTR(config=_config['loftr'])\n","        self.loss = LoFTRLoss(_config)\n","\n","        # Pretrained weights\n","        if pretrained_ckpt:\n","            state_dict = torch.load(pretrained_ckpt, map_location='cuda')['state_dict']\n","            self.matcher.load_state_dict(state_dict, strict=True)\n","            logger.info(f\"Load \\'{pretrained_ckpt}\\' as pretrained checkpoint\")\n","        \n","        # Testing\n","        self.dump_dir = dump_dir\n","        \n","    def configure_optimizers(self):\n","        # FIXME: The scheduler did not work properly when `--resume_from_checkpoint`\n","        optimizer = build_optimizer(self, self.config)\n","        scheduler = build_scheduler(self.config, optimizer)\n","        return [optimizer], [scheduler]\n","    \n","    def optimizer_step(\n","            self, epoch, batch_idx, optimizer, optimizer_idx,\n","            optimizer_closure, on_tpu, using_native_amp, using_lbfgs):\n","        # learning rate warm up\n","        warmup_step = self.config.TRAINER.WARMUP_STEP\n","        if self.trainer.global_step < warmup_step:\n","            if self.config.TRAINER.WARMUP_TYPE == 'linear':\n","                base_lr = self.config.TRAINER.WARMUP_RATIO * self.config.TRAINER.TRUE_LR\n","                lr = base_lr + \\\n","                    (self.trainer.global_step / self.config.TRAINER.WARMUP_STEP) * \\\n","                    abs(self.config.TRAINER.TRUE_LR - base_lr)\n","                for pg in optimizer.param_groups:\n","                    pg['lr'] = lr\n","            elif self.config.TRAINER.WARMUP_TYPE == 'constant':\n","                pass\n","            else:\n","                raise ValueError(f'Unknown lr warm-up strategy: {self.config.TRAINER.WARMUP_TYPE}')\n","\n","        # update params\n","        optimizer.step(closure=optimizer_closure)\n","        optimizer.zero_grad()\n","    \n","    def _trainval_inference(self, batch):\n","        with self.profiler.profile(\"Compute coarse supervision\"):\n","            compute_supervision_coarse(batch, self.config)\n","        \n","        with self.profiler.profile(\"LoFTR\"):\n","            self.matcher(batch)\n","        \n","        with self.profiler.profile(\"Compute fine supervision\"):\n","            compute_supervision_fine(batch, self.config)\n","            \n","        with self.profiler.profile(\"Compute losses\"):\n","            self.loss(batch)\n","    \n","    def _compute_metrics(self, batch):\n","        with self.profiler.profile(\"Copmute metrics\"):\n","            compute_symmetrical_epipolar_errors(batch)  # compute epi_errs for each match\n","            compute_pose_errors(batch, self.config)  # compute R_errs, t_errs, pose_errs for each pair\n","\n","            rel_pair_names = list(zip(*batch['pair_names']))\n","            bs = batch['image0'].size(0)\n","            metrics = {\n","                # to filter duplicate pairs caused by DistributedSampler\n","                'identifiers': ['#'.join(rel_pair_names[b]) for b in range(bs)],\n","                'epi_errs': [batch['epi_errs'][batch['m_bids'] == b].cpu().numpy() for b in range(bs)],\n","                'R_errs': batch['R_errs'],\n","                't_errs': batch['t_errs'],\n","                'inliers': batch['inliers']}\n","            ret_dict = {'metrics': metrics}\n","        return ret_dict, rel_pair_names\n","    \n","    def training_step(self, batch, batch_idx):\n","        self._trainval_inference(batch)\n","        \n","        # logging\n","        if self.trainer.global_rank == 0 and self.global_step % self.trainer.log_every_n_steps == 0:\n","            # scalars\n","            for k, v in batch['loss_scalars'].items():\n","                self.logger.experiment.add_scalar(f'train/{k}', v, self.global_step)\n","\n","            # net-params\n","            if self.config.LOFTR.MATCH_COARSE.MATCH_TYPE == 'sinkhorn':\n","                self.logger.experiment.add_scalar(\n","                    f'skh_bin_score', self.matcher.coarse_matching.bin_score.clone().detach().cpu().data, self.global_step)\n","\n","            # figures\n","            if self.config.TRAINER.ENABLE_PLOTTING:\n","                compute_symmetrical_epipolar_errors(batch)  # compute epi_errs for each match\n","                figures = make_matching_figures(batch, self.config, self.config.TRAINER.PLOT_MODE)\n","                for k, v in figures.items():\n","                    self.logger.experiment.add_figure(f'train_match/{k}', v, self.global_step)\n","        gc.collect()\n","        torch.cuda.empty_cache()\n","        return {'loss': batch['loss']}\n","\n","    def training_epoch_end(self, outputs):\n","        avg_loss = torch.stack([x['loss'] for x in outputs]).mean()\n","        if self.trainer.global_rank == 0:\n","            self.logger.experiment.add_scalar(\n","                'train/avg_loss_on_epoch', avg_loss,\n","                global_step=self.current_epoch)\n","        gc.collect()\n","        torch.cuda.empty_cache()\n","    \n","    def validation_step(self, batch, batch_idx):\n","        self._trainval_inference(batch)\n","        \n","        ret_dict, _ = self._compute_metrics(batch)\n","        \n","        val_plot_interval = max(self.trainer.num_val_batches[0] // self.n_vals_plot, 1)\n","        figures = {self.config.TRAINER.PLOT_MODE: []}\n","        if batch_idx % val_plot_interval == 0:\n","            figures = make_matching_figures(batch, self.config, mode=self.config.TRAINER.PLOT_MODE)\n","        gc.collect()\n","        torch.cuda.empty_cache()\n","        return {\n","            **ret_dict,\n","            'loss_scalars': batch['loss_scalars'],\n","            'figures': figures,\n","        }\n","        \n","    def validation_epoch_end(self, outputs):\n","        # handle multiple validation sets\n","        multi_outputs = [outputs] if not isinstance(outputs[0], (list, tuple)) else outputs\n","        multi_val_metrics = defaultdict(list)\n","        \n","        for valset_idx, outputs in enumerate(multi_outputs):\n","            # since pl performs sanity_check at the very begining of the training\n","            cur_epoch = self.trainer.current_epoch\n","            if not self.trainer.resume_from_checkpoint :\n","                cur_epoch = -1\n","\n","            # 1. loss_scalars: dict of list, on cpu\n","            _loss_scalars = [o['loss_scalars'] for o in outputs]\n","            loss_scalars = {k: flattenList(all_gather([_ls[k] for _ls in _loss_scalars])) for k in _loss_scalars[0]}\n","\n","            # 2. val metrics: dict of list, numpy\n","            _metrics = [o['metrics'] for o in outputs]\n","            metrics = {k: flattenList(all_gather(flattenList([_me[k] for _me in _metrics]))) for k in _metrics[0]}\n","            # NOTE: all ranks need to `aggregate_merics`, but only log at rank-0 \n","            val_metrics_4tb = aggregate_metrics(metrics, self.config.TRAINER.EPI_ERR_THR)\n","            for thr in [5, 10, 20]:\n","                multi_val_metrics[f'auc@{thr}'].append(val_metrics_4tb[f'auc@{thr}'])\n","            \n","            # 3. figures\n","            _figures = [o['figures'] for o in outputs]\n","            figures = {k: flattenList(gather(flattenList([_me[k] for _me in _figures]))) for k in _figures[0]}\n","\n","            # tensorboard records only on rank 0\n","            if self.trainer.global_rank == 0:\n","                for k, v in loss_scalars.items():\n","                    mean_v = torch.stack(v).mean()\n","                    self.logger.experiment.add_scalar(f'val_{valset_idx}/avg_{k}', mean_v, global_step=cur_epoch)\n","\n","                for k, v in val_metrics_4tb.items():\n","                    self.logger.experiment.add_scalar(f\"metrics_{valset_idx}/{k}\", v, global_step=cur_epoch)\n","                \n","            gc.collect()\n","            torch.cuda.empty_cache()   \n","            plt.close('all')\n","\n","        for thr in [5, 10, 20]:\n","            # log on all ranks for ModelCheckpoint callback to work properly\n","            self.log(f'auc@{thr}', torch.tensor(np.mean(multi_val_metrics[f'auc@{thr}'])))  # ckpt monitors on this\n","\n","    def test_step(self, batch, batch_idx):\n","        with self.profiler.profile(\"LoFTR\"):\n","            self.matcher(batch)\n","\n","        ret_dict, rel_pair_names = self._compute_metrics(batch)\n","\n","        with self.profiler.profile(\"dump_results\"):\n","            if self.dump_dir is not None:\n","                # dump results for further analysis\n","                keys_to_save = {'mkpts0_f', 'mkpts1_f', 'mconf', 'epi_errs'}\n","                pair_names = list(zip(*batch['pair_names']))\n","                bs = batch['image0'].shape[0]\n","                dumps = []\n","                for b_id in range(bs):\n","                    item = {}\n","                    mask = batch['m_bids'] == b_id\n","                    item['pair_names'] = pair_names[b_id]\n","                    item['identifier'] = '#'.join(rel_pair_names[b_id])\n","                    for key in keys_to_save:\n","                        item[key] = batch[key][mask].cpu().numpy()\n","                    for key in ['R_errs', 't_errs', 'inliers']:\n","                        item[key] = batch[key][b_id]\n","                    dumps.append(item)\n","                ret_dict['dumps'] = dumps\n","\n","        return ret_dict\n","\n","    def test_epoch_end(self, outputs):\n","        # metrics: dict of list, numpy\n","        _metrics = [o['metrics'] for o in outputs]\n","        metrics = {k: flattenList(gather(flattenList([_me[k] for _me in _metrics]))) for k in _metrics[0]}\n","\n","        # [{key: [{...}, *#bs]}, *#batch]\n","        if self.dump_dir is not None:\n","            Path(self.dump_dir).mkdir(parents=True, exist_ok=True)\n","            _dumps = flattenList([o['dumps'] for o in outputs])  # [{...}, #bs*#batch]\n","            dumps = flattenList(gather(_dumps))  # [{...}, #proc*#bs*#batch]\n","            logger.info(f'Prediction and evaluation results will be saved to: {self.dump_dir}')\n","\n","        if self.trainer.global_rank == 0:\n","            print(self.profiler.summary())\n","            val_metrics_4tb = aggregate_metrics(metrics, self.config.TRAINER.EPI_ERR_THR)\n","            logger.info('\\n' + pprint.pformat(val_metrics_4tb))\n","            if self.dump_dir is not None:\n","                np.save(Path(self.dump_dir) / 'LoFTR_pred_eval', dumps)"]},{"cell_type":"code","execution_count":null,"id":"ef0585c5","metadata":{"execution":{"iopub.execute_input":"2022-04-17T18:15:22.456688Z","iopub.status.busy":"2022-04-17T18:15:22.455974Z","iopub.status.idle":"2022-04-17T18:15:22.461827Z","shell.execute_reply":"2022-04-17T18:15:22.461132Z"},"papermill":{"duration":0.051337,"end_time":"2022-04-17T18:15:22.463647","exception":false,"start_time":"2022-04-17T18:15:22.412310","status":"completed"},"tags":[],"id":"ef0585c5"},"outputs":[],"source":[" \n","def read_megadepth_depth(path, pad_to=None):\n","    depth = cv2.imread(path, 0)\n","    if pad_to is not None:\n","        depth, _ = pad_bottom_right(depth, pad_to, ret_mask=False)\n","    depth = torch.from_numpy(depth).float()  # (h, w)\n","    gc.collect()\n","    return depth"]},{"cell_type":"code","execution_count":null,"id":"4117ee5b","metadata":{"execution":{"iopub.execute_input":"2022-04-17T18:15:22.523301Z","iopub.status.busy":"2022-04-17T18:15:22.523055Z","iopub.status.idle":"2022-04-17T18:15:22.575207Z","shell.execute_reply":"2022-04-17T18:15:22.574441Z"},"papermill":{"duration":0.084463,"end_time":"2022-04-17T18:15:22.577342","exception":false,"start_time":"2022-04-17T18:15:22.492879","status":"completed"},"tags":[],"id":"4117ee5b"},"outputs":[],"source":["import os.path as osp\n","import numpy as np\n","import torch\n","import torch.nn.functional as F\n","from torch.utils.data import Dataset\n","from loguru import logger\n","\n","from src.utils.dataset import read_megadepth_gray, pad_bottom_right\n","\n","\n","class MegaDepthDataset(Dataset):\n","    def __init__(self,\n","                 data,\n","                 npz_path,\n","                 mode='train',\n","                 min_overlap_score=0.4,\n","                 img_resize=None,\n","                 df=None,\n","                 img_padding=False,\n","                 depth_padding=False,\n","                 augment_fn=None,\n","                 **kwargs):\n","        \"\"\"\n","        Manage one scene(npz_path) of MegaDepth dataset.\n","        \n","        Args:\n","            root_dir (str): megadepth root directory that has `phoenix`.\n","            npz_path (str): {scene_id}.npz path. This contains image pair information of a scene.\n","            mode (str): options are ['train', 'val', 'test']\n","            min_overlap_score (float): how much a pair should have in common. In range of [0, 1]. Set to 0 when testing.\n","            img_resize (int, optional): the longer edge of resized images. None for no resize. 640 is recommended.\n","                                        This is useful during training with batches and testing with memory intensive algorithms.\n","            df (int, optional): image size division factor. NOTE: this will change the final image size after img_resize.\n","            img_padding (bool): If set to 'True', zero-pad the image to squared size. This is useful during training.\n","            depth_padding (bool): If set to 'True', zero-pad depthmap to (2000, 2000). This is useful during training.\n","            augment_fn (callable, optional): augments images with pre-defined visual effects.\n","        \"\"\"\n","        super().__init__()\n","    # self.root_dir = root_dir\n","        self.mode = mode\n","\n","        # prepare scene_info and pair_info\n","        if mode == 'test' and min_overlap_score != 0:\n","            logger.warning(\"You are using `min_overlap_score`!=0 in test mode. Set to 0.\")\n","            min_overlap_score = 0\n","\n","        # parameters for image resizing, padding and depthmap padding\n","        if mode == 'train':\n","            assert img_resize is not None and img_padding and depth_padding\n","        self.img_resize = img_resize\n","        self.df = df\n","        self.img_padding = img_padding\n","        self.depth_max_size = 2000 if depth_padding else None  # the upperbound of depthmaps size in megadepth.\n","\n","        # for training LoFTR\n","        self.augment_fn = augment_fn if mode == 'train' else None\n","        self.coarse_scale = getattr(kwargs, 'coarse_scale', 0.125)\n","        self.path1 = data[\"path1\"].values\n","        self.path2 = data[\"path2\"].values\n","        self.camerainst1 = data[\"camerainst1\"].values\n","        self.camerainst2 = data[\"camerainst2\"].values\n","        self.rot1 = data[\"rot1\"].values\n","        self.rot2 = data[\"rot2\"].values\n","        self.trans1 = data[\"trans1\"].values\n","        self.trans2 = data[\"trans2\"].values\n","        gc.collect()\n","        \n","    def __len__(self):\n","        return len(self.path1)\n","\n","    def __getitem__(self, idx):\n","        # read grayscale image and mask. (1, h, w) and (h, w)\n","        img_name0 = self.path1[idx]\n","        img_name1 = self.path2[idx]\n","        \n","        # TODO: Support augmentation & handle seeds for each worker correctly.\n","        image0, mask0, scale0 = read_megadepth_gray(\n","            img_name0, self.img_resize, self.df, self.img_padding, None)\n","            # np.random.choice([self.augment_fn, None], p=[0.5, 0.5]))\n","        image1, mask1, scale1 = read_megadepth_gray(\n","            img_name1, self.img_resize, self.df, self.img_padding, None)\n","            # np.random.choice([self.augment_fn, None], p=[0.5, 0.5]))\n","        depth_path0 = \"depth_maps/\" + img_name0.split(\"/\")[-3] + '/' + img_name0.split(\"/\")[-1]\n","        depth_path1 = \"depth_maps/\" + img_name1.split(\"/\")[-3] + '/' + img_name1.split(\"/\")[-1]\n","        \n","        # read depth. shape: (h, w)\n","        if self.mode in ['train', 'val']:\n","            depth0 = read_megadepth_depth(\n","                depth_path0, pad_to=self.depth_max_size)\n","            depth1 = read_megadepth_depth(\n","                depth_path1, pad_to=self.depth_max_size)\n","        else:\n","            depth0 = depth1 = torch.tensor([])\n","\n","        # read intrinsics of original size\n","        K_0 = torch.tensor(np.asarray([float(x) for x in self.camerainst1[idx].split(\" \")]), dtype=torch.float).reshape(3, 3)\n","        K_1 = torch.tensor(np.asarray([float(x) for x in self.camerainst2[idx].split(\" \")]), dtype=torch.float).reshape(3, 3)\n","\n","        # read and compute relative poses\n","        R0 = self.rot1[idx].replace('{','').replace('}','').replace(\"'\", \"\")        \n","        R0 = np.asarray([float(x) for x in R0.split(\" \")]).reshape(3, 3)\n","        Tv0 = self.trans1[idx].replace('{','').replace('}','').replace(\"'\", \"\")\n","        Tv0 = np.asarray([[float(x) for x in Tv0.split(\" \")]])\n","        T0 = np.concatenate((R0, Tv0.T), axis=1)\n","        T0 = np.concatenate((T0, np.asarray([[0, 0, 0, 1]])), axis=0)\n","        del R0\n","        del Tv0\n","        R1 = self.rot2[idx].replace('{','').replace('}','').replace(\"'\", \"\")\n","        R1 = np.asarray([float(x) for x in R1.split(\" \")]).reshape(3, 3)\n","        Tv1 = self.trans2[idx].replace('{','').replace('}','').replace(\"'\", \"\")\n","        Tv1 = np.asarray([[float(x) for x in Tv1.split(\" \")]])\n","        T1 = np.concatenate((R1, Tv1.T), axis=1)\n","        T1 = np.concatenate((T1, np.asarray([[0, 0, 0, 1]])), axis=0)\n","        del R1\n","        del Tv1\n","        T_0to1 = torch.tensor(np.matmul(T1, np.linalg.inv(T0)), dtype=torch.float)[:4, :4]  # (4, 4)\n","        T_1to0 = T_0to1.inverse()\n","\n","        data = {\n","            'image0': image0,  # (1, h, w)\n","            'depth0': depth0,  # (h, w)\n","            'image1': image1,\n","            'depth1': depth1,\n","            'T_0to1': T_0to1,  # (4, 4)\n","            'T_1to0': T_1to0,\n","            'K0': K_0,  # (3, 3)\n","            'K1': K_1,\n","            'scale0': scale0,  # [scale_w, scale_h]\n","            'scale1': scale1,\n","            'dataset_name': 'MegaDepth',\n","            'scene_id': idx,\n","            'pair_id': idx,\n","            'pair_names': (img_name0, img_name1),\n","        }\n","\n","        # for LoFTR training\n","        if mask0 is not None:  # img_padding is True\n","            if self.coarse_scale:\n","                [ts_mask_0, ts_mask_1] = F.interpolate(torch.stack([mask0, mask1], dim=0)[None].float(),\n","                                                       scale_factor=self.coarse_scale,\n","                                                       mode='nearest',\n","                                                       recompute_scale_factor=False)[0].bool()\n","            data.update({'mask0': ts_mask_0, 'mask1': ts_mask_1})\n","        del image0\n","        del image1\n","        del depth0\n","        del depth1\n","        gc.collect()\n","        torch.cuda.empty_cache()\n","        return data"]},{"cell_type":"code","execution_count":null,"id":"51f23d81","metadata":{"execution":{"iopub.execute_input":"2022-04-17T18:15:22.639499Z","iopub.status.busy":"2022-04-17T18:15:22.639076Z","iopub.status.idle":"2022-04-17T18:15:24.119130Z","shell.execute_reply":"2022-04-17T18:15:24.118393Z"},"papermill":{"duration":1.513613,"end_time":"2022-04-17T18:15:24.121113","exception":false,"start_time":"2022-04-17T18:15:22.607500","status":"completed"},"tags":[],"id":"51f23d81"},"outputs":[],"source":["import os\n","import math\n","from collections import abc\n","from loguru import logger\n","from torch.utils.data.dataset import Dataset\n","from tqdm import tqdm\n","from os import path as osp\n","from pathlib import Path\n","from joblib import Parallel, delayed\n","\n","import pytorch_lightning as pl\n","from torch import distributed as dist\n","from torch.utils.data import (\n","    Dataset,\n","    DataLoader,\n","    ConcatDataset,\n","    DistributedSampler,\n","    RandomSampler,\n","    dataloader\n",")\n","\n","from src.utils.augment import build_augmentor\n","from src.utils.dataloader import get_local_split\n","from src.utils.misc import tqdm_joblib\n","from src.utils import comm\n","\n","\n","from src.datasets.sampler import RandomConcatSampler\n","\n","\n","class MultiSceneDataModule(pl.LightningDataModule):\n","    \"\"\" \n","    For distributed training, each training process is assgined\n","    only a part of the training scenes to reduce memory overhead.\n","    \"\"\"\n","    def __init__(self, args, config ,data):\n","        super().__init__()\n","\n","        # 1. data config\n","        # Train and Val should from the same data source\n","        self.trainval_data_source = config.DATASET.TRAINVAL_DATA_SOURCE\n","        self.test_data_source = config.DATASET.TEST_DATA_SOURCE\n","        # training and validating\n","        self.train_data = data\n","        self.train_pose_root = config.DATASET.TRAIN_POSE_ROOT  # (optional)\n","        self.train_npz_root = config.DATASET.TRAIN_NPZ_ROOT\n","        self.train_list_path = config.DATASET.TRAIN_LIST_PATH\n","        self.train_intrinsic_path = config.DATASET.TRAIN_INTRINSIC_PATH\n","        self.val_data = data\n","        self.val_pose_root = config.DATASET.VAL_POSE_ROOT  # (optional)\n","        self.val_npz_root = config.DATASET.VAL_NPZ_ROOT\n","        self.val_list_path = config.DATASET.VAL_LIST_PATH\n","        self.val_intrinsic_path = config.DATASET.VAL_INTRINSIC_PATH\n","        # testing\n","        self.test_data = data\n","        self.test_pose_root = config.DATASET.TEST_POSE_ROOT  # (optional)\n","        self.test_npz_root = config.DATASET.TEST_NPZ_ROOT\n","        self.test_list_path = config.DATASET.TEST_LIST_PATH\n","        self.test_intrinsic_path = config.DATASET.TEST_INTRINSIC_PATH\n","\n","        # 2. dataset config\n","        # general options\n","        self.min_overlap_score_test = config.DATASET.MIN_OVERLAP_SCORE_TEST  # 0.4, omit data with overlap_score < min_overlap_score\n","        self.min_overlap_score_train = config.DATASET.MIN_OVERLAP_SCORE_TRAIN\n","        self.augment_fn = build_augmentor(config.DATASET.AUGMENTATION_TYPE)  # None, options: [None, 'dark', 'mobile']\n","\n","        # MegaDepth options\n","        self.mgdpt_img_resize = config.DATASET.MGDPT_IMG_RESIZE  # 840\n","        self.mgdpt_img_pad = config.DATASET.MGDPT_IMG_PAD   # True\n","        self.mgdpt_depth_pad = config.DATASET.MGDPT_DEPTH_PAD   # True\n","        self.mgdpt_df = config.DATASET.MGDPT_DF  # 8\n","        self.coarse_scale = 1 / config.LOFTR.RESOLUTION[0]  # 0.125. for training loftr.\n","\n","        # 3.loader parameters\n","        self.train_loader_params = {\n","            'batch_size': args.batch_size,\n","            'num_workers': args.num_workers,\n","            'pin_memory': getattr(args, 'pin_memory', True)\n","        }\n","        self.val_loader_params = {\n","            'batch_size': 1,\n","            'shuffle': False,\n","            'num_workers': args.num_workers,\n","            'pin_memory': getattr(args, 'pin_memory', True)\n","        }\n","        self.test_loader_params = {\n","            'batch_size': 1,\n","            'shuffle': False,\n","            'num_workers': args.num_workers,\n","            'pin_memory': True\n","        }\n","        \n","        # 4. sampler\n","        self.data_sampler = config.TRAINER.DATA_SAMPLER\n","        self.n_samples_per_subset = config.TRAINER.N_SAMPLES_PER_SUBSET\n","        self.subset_replacement = config.TRAINER.SB_SUBSET_SAMPLE_REPLACEMENT\n","        self.shuffle = config.TRAINER.SB_SUBSET_SHUFFLE\n","        self.repeat = config.TRAINER.SB_REPEAT\n","        \n","        # (optional) RandomSampler for debugging\n","\n","        # misc configurations\n","        self.parallel_load_data = getattr(args, 'parallel_load_data', False)\n","        self.seed = config.TRAINER.SEED  # 66\n","\n","    def setup(self, stage=None):\n","        \"\"\"\n","        Setup train / val / test dataset. This method will be called by PL automatically.\n","        Args:\n","            stage (str): 'fit' in training phase, and 'test' in testing phase.\n","        \"\"\"\n","\n","        assert stage in ['fit', 'test'], \"stage must be either fit or test\"\n","\n","\n","        if stage == 'fit':\n","            self.train_dataset = self._setup_dataset(\n","                self.train_data,\n","                self.train_npz_root,\n","                self.train_list_path,\n","                self.train_intrinsic_path,\n","                mode='train',\n","                min_overlap_score=self.min_overlap_score_train,\n","                pose_dir=self.train_pose_root)\n","            # setup multiple (optional) validation subsets\n","            \n","            self.val_dataset = self._setup_dataset(\n","                self.val_data,\n","                self.val_npz_root,\n","                self.val_list_path,\n","                self.val_intrinsic_path,\n","                mode='val',\n","                min_overlap_score=self.min_overlap_score_test,\n","                pose_dir=self.val_pose_root)\n","            \n","        else:  # stage == 'test\n","            self.test_dataset = self._setup_dataset(\n","                self.test_data,\n","                self.test_npz_root,\n","                self.test_list_path,\n","                self.test_intrinsic_path,\n","                mode='test',\n","                min_overlap_score=self.min_overlap_score_test,\n","                pose_dir=self.test_pose_root)\n","            \n","\n","    def _setup_dataset(self,\n","                       data,\n","                       split_npz_root,\n","                       scene_list_path,\n","                       intri_path,\n","                       mode='train',\n","                       min_overlap_score=0.,\n","                       pose_dir=None):\n","        \"\"\" Setup train / val / test set\"\"\"\n","        local_npz_names = \"\"\n","        dataset_builder = self._build_concat_dataset\n","        return dataset_builder(data, local_npz_names, split_npz_root, intri_path,\n","                                mode=mode, min_overlap_score=min_overlap_score, pose_dir=pose_dir)\n","\n","    def _build_concat_dataset(\n","        self,\n","        data,\n","        npz_names,\n","        npz_dir,\n","        intrinsic_path,\n","        mode,\n","        min_overlap_score=0.,\n","        pose_dir=None\n","    ):\n","        datasets = []\n","        augment_fn = self.augment_fn if mode == 'train' else None\n","        data_source = self.trainval_data_source if mode in ['train', 'val'] else self.test_data_source\n","        npz_path = \"\"\n","        \n","        datasets.append(\n","            MegaDepthDataset(data,\n","                             npz_path,\n","                             mode=mode,\n","                             min_overlap_score=min_overlap_score,\n","                             img_resize=self.mgdpt_img_resize,\n","                             df=self.mgdpt_df,\n","                             img_padding=self.mgdpt_img_pad,\n","                             depth_padding=self.mgdpt_depth_pad,\n","                             augment_fn=augment_fn,\n","                             coarse_scale=self.coarse_scale))\n","        return ConcatDataset(datasets)\n","    \n","\n","    def train_dataloader(self):\n","        \"\"\" Build training dataloader for ScanNet / MegaDepth. \"\"\"\n","#         assert self.data_sampler in ['scene_balance']\n","#         #logger.info(f'[rank:{self.rank}/{self.world_size}]: Train Sampler and DataLoader re-init (should not re-init between epochs!).')\n","#         if self.data_sampler == 'scene_balance':\n","#             sampler = RandomConcatSampler(self.train_dataset,\n","#                                           self.n_samples_per_subset,\n","#                                           self.subset_replacement,\n","#                                           self.shuffle, self.repeat, self.seed)\n","#         else:\n","#             sampler = None\n","        dataloader = DataLoader(self.train_dataset, batch_size=1, \n","                              shuffle=False, \n","                              num_workers=0, pin_memory=True, drop_last=True)\n","        return dataloader\n","    \n","    def val_dataloader(self):\n","        \"\"\" Build validation dataloader for ScanNet / MegaDepth. \"\"\"\n","        #logger.info(f'[rank:{self.rank}/{self.world_size}]: Val Sampler and DataLoader re-init.')\n","        dataloader = DataLoader(self.val_dataset, batch_size=1, \n","                              shuffle=False, \n","                              num_workers=0, pin_memory=True, drop_last=True)\n","        return dataloader\n","\n","    def test_dataloader(self, *args, **kwargs):\n","        #logger.info(f'[rank:{self.rank}/{self.world_size}]: Test Sampler and DataLoader re-init.')\n","        sampler = DistributedSampler(self.test_dataset, shuffle=False)\n","        return DataLoader(self.test_dataset, sampler=sampler, **self.test_loader_params)\n","\n","\n","def _build_dataset(dataset: Dataset, *args, **kwargs):\n","    return dataset(*args, **kwargs)"]},{"cell_type":"code","execution_count":null,"id":"651abfbc","metadata":{"execution":{"iopub.execute_input":"2022-04-17T18:15:24.160007Z","iopub.status.busy":"2022-04-17T18:15:24.159428Z","iopub.status.idle":"2022-04-17T18:15:24.190873Z","shell.execute_reply":"2022-04-17T18:15:24.190262Z"},"papermill":{"duration":0.052868,"end_time":"2022-04-17T18:15:24.192410","exception":false,"start_time":"2022-04-17T18:15:24.139542","status":"completed"},"tags":[],"id":"651abfbc"},"outputs":[],"source":["import math\n","import argparse\n","import pprint\n","from distutils.util import strtobool\n","from pathlib import Path\n","from loguru import logger as loguru_logger\n","\n","import pytorch_lightning as pl\n","from pytorch_lightning.utilities import rank_zero_only\n","from pytorch_lightning.loggers import TensorBoardLogger\n","from pytorch_lightning.callbacks import ModelCheckpoint, LearningRateMonitor\n","from pytorch_lightning.plugins import DDPPlugin\n","\n","from src.config.default import get_cfg_defaults\n","from src.utils.misc import get_rank_zero_only_logger, setup_gpus\n","from src.utils.profiler import build_profiler\n","import pandas as pd\n","loguru_logger = get_rank_zero_only_logger(loguru_logger)\n","\n","def parse_args():\n","    # init a costum parser which will be added into pl.Trainer parser\n","    # check documentation: https://pytorch-lightning.readthedocs.io/en/latest/common/trainer.html#trainer-flags\n","    parser = argparse.ArgumentParser(formatter_class=argparse.ArgumentDefaultsHelpFormatter)\n","    parser.add_argument(\n","        'data_cfg_path', type=str, help='data config path')\n","    parser.add_argument(\n","        'main_cfg_path', type=str, help='main config path')\n","    parser.add_argument(\n","        '--exp_name', type=str, default='default_exp_name')\n","    parser.add_argument(\n","        '--batch_size', type=int, default=4, help='batch_size per gpu')\n","    parser.add_argument(\n","        '--num_workers', type=int, default=4)\n","    parser.add_argument(\n","        '--pin_memory', type=lambda x: bool(strtobool(x)),\n","        nargs='?', default=True, help='whether loading data to pinned memory or not')\n","    parser.add_argument(\n","        '--ckpt_path', type=str, default=\"../input/kornia-loftr/outdoor_ds.ckpt\",\n","        help='pretrained checkpoint path, helpful for using a pre-trained coarse-only LoFTR')\n","    parser.add_argument(\n","        '--disable_ckpt', action='store_true',\n","        help='disable checkpoint saving (useful for debugging).')\n","    parser.add_argument(\n","        '--profiler_name', type=str, default=None,\n","        help='options: [inference, pytorch], or leave it unset')\n","    parser.add_argument(\n","        '--parallel_load_data', action='store_true',\n","        help='load datasets in with multiple processes.')\n","\n","    parser = pl.Trainer.add_argparse_args(parser)\n","    return parser.parse_args('../input/loftrutils/LoFTR-master/LoFTR-master/configs/data/megadepth_trainval_640.py ../input/loftrutils/LoFTR-master/LoFTR-master/configs/loftr/outdoor/loftr_ds_dense.py --exp_name test --gpus 0 --num_nodes 0 --accelerator gpu --batch_size 1 --check_val_every_n_epoch 1 --log_every_n_steps 1 --flush_logs_every_n_steps 1 --limit_val_batches 1 --num_sanity_val_steps 10 --benchmark True --max_epochs 4'.split())\n","\n","\n","def train():\n","    # parse arguments\n","    args = parse_args()\n","    rank_zero_only(pprint.pprint)(vars(args))\n","\n","    # init default-cfg and merge it with the main- and data-cfg\n","    config = get_cfg_defaults()\n","    config.merge_from_file(args.main_cfg_path)\n","    config.merge_from_file(args.data_cfg_path)\n","    pl.seed_everything(config.TRAINER.SEED)  # reproducibility\n","    # TODO: Use different seeds for each dataloader workers\n","    # This is needed for data augmentation\n","    \n","    # scale lr and warmup-step automatically\n","    args.gpus = _n_gpus = setup_gpus(args.gpus)\n","    config.TRAINER.WORLD_SIZE = _n_gpus * args.num_nodes\n","    config.TRAINER.TRUE_BATCH_SIZE = config.TRAINER.WORLD_SIZE * args.batch_size\n","    _scaling = 1#config.TRAINER.TRUE_BATCH_SIZE / config.TRAINER.CANONICAL_BS\n","    config.TRAINER.SCALING = _scaling\n","    config.TRAINER.TRUE_LR = 0.00001 * _scaling\n","    config.TRAINER.WARMUP_STEP = math.floor(config.TRAINER.WARMUP_STEP / _scaling)\n","    \n","    # lightning module\n","    profiler = build_profiler(args.profiler_name)\n","    model = PL_LoFTR(config, pretrained_ckpt=args.ckpt_path, profiler=profiler)\n","    loguru_logger.info(f\"LoFTR LightningModule initialized!\")\n","    \n","    # lightning data\n","    data = pd.read_csv(\"train_gt.csv\")\n","    data_module = MultiSceneDataModule(args, config, data[:100])\n","    gc.collect()\n","    loguru_logger.info(f\"LoFTR DataModule initialized!\")\n","    \n","    # TensorBoard Logger\n","    logger = TensorBoardLogger(save_dir='logs/tb_logs', name=args.exp_name, default_hp_metric=False)\n","    ckpt_dir = Path(logger.log_dir) / 'checkpoints'\n","    \n","    # Callbacks\n","    # TODO: update ModelCheckpoint to monitor multiple metrics\n","    ckpt_callback = ModelCheckpoint(monitor='auc@10', verbose=True, save_top_k=5, mode='max',\n","                                    save_last=True,\n","                                    dirpath=str(ckpt_dir),\n","                                    filename='{epoch}-{auc@5:.3f}-{auc@10:.3f}-{auc@20:.3f}')\n","    lr_monitor = LearningRateMonitor(logging_interval='step')\n","    callbacks = [lr_monitor]\n","    if not args.disable_ckpt:\n","        callbacks.append(ckpt_callback)\n","    \n","    # Lightning Trainer\n","    trainer = pl.Trainer.from_argparse_args(\n","        args,\n","#         plugins=DDPPlugin(find_unused_parameters=False,\n","#                           num_nodes=args.num_nodes,\n","#                           sync_batchnorm=config.TRAINER.WORLD_SIZE > 0),\n","        gradient_clip_val=config.TRAINER.GRADIENT_CLIPPING,\n","        callbacks=callbacks,\n","        logger=logger,\n","        #sync_batchnorm=config.TRAINER.WORLD_SIZE > 0,\n","        replace_sampler_ddp=False,  # use custom sampler\n","          # avoid repeated samples!\n","        weights_summary='full',\n","        profiler=profiler)\n","    loguru_logger.info(f\"Trainer initialized!\")\n","    loguru_logger.info(f\"Start training!\")\n","    trainer.fit(model, datamodule=data_module)\n"]},{"cell_type":"code","execution_count":null,"id":"54bf4cb2","metadata":{"execution":{"iopub.execute_input":"2022-04-17T18:15:24.229901Z","iopub.status.busy":"2022-04-17T18:15:24.229369Z","iopub.status.idle":"2022-04-17T18:55:22.980201Z","shell.execute_reply":"2022-04-17T18:55:22.979462Z"},"papermill":{"duration":2398.77152,"end_time":"2022-04-17T18:55:22.982215","exception":false,"start_time":"2022-04-17T18:15:24.210695","status":"completed"},"tags":[],"colab":{"referenced_widgets":["55fabe4c97e447c6aed34c954d8c1b67","4d29c990a39247c88ce4c441c394a19f","171d07b300d34c308c2ab82b7b347ce4","ee528cb255ac4ba5b4f78091f57c17a6","ac4f19dccac04db8bbe7a440bb2a23b5","38520d177ad34b5bb51368c1420d9eac"]},"id":"54bf4cb2","outputId":"d22bbcb1-9621-43a9-9001-7142a3682e94"},"outputs":[{"name":"stdout","output_type":"stream","text":["{'accelerator': 'gpu',\n"," 'accumulate_grad_batches': None,\n"," 'amp_backend': 'native',\n"," 'amp_level': None,\n"," 'auto_lr_find': False,\n"," 'auto_scale_batch_size': False,\n"," 'auto_select_gpus': False,\n"," 'batch_size': 1,\n"," 'benchmark': True,\n"," 'check_val_every_n_epoch': 1,\n"," 'checkpoint_callback': None,\n"," 'ckpt_path': '../input/kornia-loftr/outdoor_ds.ckpt',\n"," 'data_cfg_path': '../input/loftrutils/LoFTR-master/LoFTR-master/configs/data/megadepth_trainval_640.py',\n"," 'default_root_dir': None,\n"," 'detect_anomaly': False,\n"," 'deterministic': False,\n"," 'devices': None,\n"," 'disable_ckpt': False,\n"," 'enable_checkpointing': True,\n"," 'enable_model_summary': True,\n"," 'enable_progress_bar': True,\n"," 'exp_name': 'test',\n"," 'fast_dev_run': False,\n"," 'flush_logs_every_n_steps': 1,\n"," 'gpus': 0,\n"," 'gradient_clip_algorithm': None,\n"," 'gradient_clip_val': None,\n"," 'ipus': None,\n"," 'limit_predict_batches': None,\n"," 'limit_test_batches': None,\n"," 'limit_train_batches': None,\n"," 'limit_val_batches': 1,\n"," 'log_every_n_steps': 1,\n"," 'log_gpu_memory': None,\n"," 'logger': True,\n"," 'main_cfg_path': '../input/loftrutils/LoFTR-master/LoFTR-master/configs/loftr/outdoor/loftr_ds_dense.py',\n"," 'max_epochs': 4,\n"," 'max_steps': -1,\n"," 'max_time': None,\n"," 'min_epochs': None,\n"," 'min_steps': None,\n"," 'move_metrics_to_cpu': False,\n"," 'multiple_trainloader_mode': 'max_size_cycle',\n"," 'num_nodes': 0,\n"," 'num_processes': None,\n"," 'num_sanity_val_steps': 10,\n"," 'num_workers': 4,\n"," 'overfit_batches': 0.0,\n"," 'parallel_load_data': False,\n"," 'pin_memory': True,\n"," 'plugins': None,\n"," 'precision': 32,\n"," 'prepare_data_per_node': None,\n"," 'process_position': 0,\n"," 'profiler': None,\n"," 'profiler_name': None,\n"," 'progress_bar_refresh_rate': None,\n"," 'reload_dataloaders_every_n_epochs': 0,\n"," 'replace_sampler_ddp': True,\n"," 'resume_from_checkpoint': None,\n"," 'stochastic_weight_avg': False,\n"," 'strategy': None,\n"," 'sync_batchnorm': False,\n"," 'terminate_on_nan': None,\n"," 'tpu_cores': None,\n"," 'track_grad_norm': -1,\n"," 'val_check_interval': None,\n"," 'weights_save_path': None,\n"," 'weights_summary': 'top'}\n"]},{"name":"stderr","output_type":"stream","text":["2022-04-17 18:15:29.610 | INFO     | __main__:__init__:48 - Load '../input/kornia-loftr/outdoor_ds.ckpt' as pretrained checkpoint\n","2022-04-17 18:15:29.612 | INFO     | __main__:train:79 - LoFTR LightningModule initialized!\n","2022-04-17 18:15:50.467 | INFO     | __main__:train:85 - LoFTR DataModule initialized!\n","/opt/conda/lib/python3.7/site-packages/pytorch_lightning/trainer/connectors/callback_connector.py:192: LightningDeprecationWarning: Setting `Trainer(weights_summary=full)` is deprecated in v1.5 and will be removed in v1.7. Please pass `pytorch_lightning.callbacks.model_summary.ModelSummary` with `max_depth` directly to the Trainer's `callbacks` argument instead.\n","  f\"Setting `Trainer(weights_summary={weights_summary})` is deprecated in v1.5 and will be removed\"\n","/opt/conda/lib/python3.7/site-packages/pytorch_lightning/trainer/connectors/logger_connector/logger_connector.py:62: LightningDeprecationWarning: Setting `Trainer(flush_logs_every_n_steps=1)` is deprecated in v1.5 and will be removed in v1.7. Please configure flushing in the logger instead.\n","  f\"Setting `Trainer(flush_logs_every_n_steps={flush_logs_every_n_steps})` is deprecated in v1.5 \"\n","2022-04-17 18:15:50.476 | INFO     | __main__:train:116 - Trainer initialized!\n","2022-04-17 18:15:50.476 | INFO     | __main__:train:117 - Start training!\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"55fabe4c97e447c6aed34c954d8c1b67","version_major":2,"version_minor":0},"text/plain":["Sanity Checking: 0it [00:00, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.7/site-packages/torch/_tensor.py:575: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.\n","To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /usr/local/src/pytorch/aten/src/ATen/native/BinaryOps.cpp:461.)\n","  return torch.floor_divide(self, other)\n","2022-04-17 18:16:00.983 | INFO     | src.utils.metrics:aggregate_metrics:182 - Aggregating metrics over 1 unique items...\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"4d29c990a39247c88ce4c441c394a19f","version_major":2,"version_minor":0},"text/plain":["Training: 0it [00:00, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["2022-04-17 18:16:20.201 | WARNING  | src.loftr.utils.supervision:spvs_coarse:93 - No groundtruth coarse match found for: [['../input/image-matching-challenge-2022/train/british_museum/images/94345807_4553191473.jpg'], ['../input/image-matching-challenge-2022/train/british_museum/images/84932226_4352179060.jpg']]\n","2022-04-17 18:16:20.433 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n","2022-04-17 18:16:22.737 | WARNING  | src.loftr.utils.supervision:spvs_coarse:93 - No groundtruth coarse match found for: [['../input/image-matching-challenge-2022/train/british_museum/images/93658023_4980549800.jpg'], ['../input/image-matching-challenge-2022/train/british_museum/images/92199010_423632152.jpg']]\n","2022-04-17 18:16:22.969 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n","2022-04-17 18:16:25.331 | WARNING  | src.loftr.utils.supervision:spvs_coarse:93 - No groundtruth coarse match found for: [['../input/image-matching-challenge-2022/train/british_museum/images/93658023_4980549800.jpg'], ['../input/image-matching-challenge-2022/train/british_museum/images/78242267_4404579754.jpg']]\n","2022-04-17 18:16:25.564 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n","2022-04-17 18:16:50.332 | WARNING  | src.loftr.utils.supervision:spvs_coarse:93 - No groundtruth coarse match found for: [['../input/image-matching-challenge-2022/train/british_museum/images/93658023_4980549800.jpg'], ['../input/image-matching-challenge-2022/train/british_museum/images/57504314_2114264842.jpg']]\n","2022-04-17 18:16:50.569 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n","2022-04-17 18:16:53.446 | WARNING  | src.loftr.utils.supervision:spvs_coarse:93 - No groundtruth coarse match found for: [['../input/image-matching-challenge-2022/train/british_museum/images/93658023_4980549800.jpg'], ['../input/image-matching-challenge-2022/train/british_museum/images/59326840_8032269061.jpg']]\n","2022-04-17 18:16:53.679 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n","2022-04-17 18:16:56.234 | WARNING  | src.loftr.utils.supervision:spvs_coarse:93 - No groundtruth coarse match found for: [['../input/image-matching-challenge-2022/train/british_museum/images/93658023_4980549800.jpg'], ['../input/image-matching-challenge-2022/train/british_museum/images/62553151_839585618.jpg']]\n","2022-04-17 18:16:56.466 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n","2022-04-17 18:16:59.081 | WARNING  | src.loftr.utils.supervision:spvs_coarse:93 - No groundtruth coarse match found for: [['../input/image-matching-challenge-2022/train/british_museum/images/92942151_2078102935.jpg'], ['../input/image-matching-challenge-2022/train/british_museum/images/01858319_78150445.jpg']]\n","2022-04-17 18:16:59.315 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n","2022-04-17 18:17:01.994 | WARNING  | src.loftr.utils.supervision:spvs_coarse:93 - No groundtruth coarse match found for: [['../input/image-matching-challenge-2022/train/british_museum/images/92199010_423632152.jpg'], ['../input/image-matching-challenge-2022/train/british_museum/images/83025239_9530039386.jpg']]\n","2022-04-17 18:17:02.229 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n","2022-04-17 18:17:04.775 | WARNING  | src.loftr.utils.supervision:spvs_coarse:93 - No groundtruth coarse match found for: [['../input/image-matching-challenge-2022/train/british_museum/images/92199010_423632152.jpg'], ['../input/image-matching-challenge-2022/train/british_museum/images/75879177_2453112255.jpg']]\n","2022-04-17 18:17:05.008 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n","2022-04-17 18:17:10.526 | WARNING  | src.loftr.utils.supervision:spvs_coarse:93 - No groundtruth coarse match found for: [['../input/image-matching-challenge-2022/train/british_museum/images/92199010_423632152.jpg'], ['../input/image-matching-challenge-2022/train/british_museum/images/51869583_2554605419.jpg']]\n","2022-04-17 18:17:10.763 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n","2022-04-17 18:17:13.844 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n","2022-04-17 18:17:19.780 | WARNING  | src.loftr.utils.supervision:spvs_coarse:93 - No groundtruth coarse match found for: [['../input/image-matching-challenge-2022/train/british_museum/images/90250998_7086081737.jpg'], ['../input/image-matching-challenge-2022/train/british_museum/images/39461890_106560712.jpg']]\n","2022-04-17 18:17:20.012 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n","2022-04-17 18:17:25.646 | WARNING  | src.loftr.utils.supervision:spvs_coarse:93 - No groundtruth coarse match found for: [['../input/image-matching-challenge-2022/train/british_museum/images/90250998_7086081737.jpg'], ['../input/image-matching-challenge-2022/train/british_museum/images/51869583_2554605419.jpg']]\n","2022-04-17 18:17:25.878 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n","2022-04-17 18:17:34.899 | WARNING  | src.loftr.utils.supervision:spvs_coarse:93 - No groundtruth coarse match found for: [['../input/image-matching-challenge-2022/train/british_museum/images/88500284_27304784.jpg'], ['../input/image-matching-challenge-2022/train/british_museum/images/72728072_3851668437.jpg']]\n","2022-04-17 18:17:35.132 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n","2022-04-17 18:17:41.090 | WARNING  | src.loftr.utils.supervision:spvs_coarse:93 - No groundtruth coarse match found for: [['../input/image-matching-challenge-2022/train/british_museum/images/84932226_4352179060.jpg'], ['../input/image-matching-challenge-2022/train/british_museum/images/06793539_251350697.jpg']]\n","2022-04-17 18:17:41.322 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n","2022-04-17 18:17:44.132 | WARNING  | src.loftr.utils.supervision:spvs_coarse:93 - No groundtruth coarse match found for: [['../input/image-matching-challenge-2022/train/british_museum/images/84932226_4352179060.jpg'], ['../input/image-matching-challenge-2022/train/british_museum/images/14501930_447150094.jpg']]\n","2022-04-17 18:17:44.365 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n","2022-04-17 18:17:47.243 | WARNING  | src.loftr.utils.supervision:spvs_coarse:93 - No groundtruth coarse match found for: [['../input/image-matching-challenge-2022/train/british_museum/images/84932226_4352179060.jpg'], ['../input/image-matching-challenge-2022/train/british_museum/images/51869583_2554605419.jpg']]\n","2022-04-17 18:17:47.475 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n","2022-04-17 18:17:50.811 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n","2022-04-17 18:17:53.738 | WARNING  | src.loftr.utils.supervision:spvs_coarse:93 - No groundtruth coarse match found for: [['../input/image-matching-challenge-2022/train/british_museum/images/78242267_4404579754.jpg'], ['../input/image-matching-challenge-2022/train/british_museum/images/69960354_6519615529.jpg']]\n","2022-04-17 18:17:53.968 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n","2022-04-17 18:17:57.126 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n","2022-04-17 18:18:00.240 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n","2022-04-17 18:18:03.274 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n","2022-04-17 18:18:06.473 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n","2022-04-17 18:18:09.358 | WARNING  | src.loftr.utils.supervision:spvs_coarse:93 - No groundtruth coarse match found for: [['../input/image-matching-challenge-2022/train/british_museum/images/77723525_5227836172.jpg'], ['../input/image-matching-challenge-2022/train/british_museum/images/75879177_2453112255.jpg']]\n","2022-04-17 18:18:09.590 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n","2022-04-17 18:18:32.505 | WARNING  | src.loftr.utils.supervision:spvs_coarse:93 - No groundtruth coarse match found for: [['../input/image-matching-challenge-2022/train/british_museum/images/77723525_5227836172.jpg'], ['../input/image-matching-challenge-2022/train/british_museum/images/57504314_2114264842.jpg']]\n","2022-04-17 18:18:32.739 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n","2022-04-17 18:18:39.405 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n","2022-04-17 18:18:42.735 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n","2022-04-17 18:18:46.001 | WARNING  | src.loftr.utils.supervision:spvs_coarse:93 - No groundtruth coarse match found for: [['../input/image-matching-challenge-2022/train/british_museum/images/75879177_2453112255.jpg'], ['../input/image-matching-challenge-2022/train/british_museum/images/69960354_6519615529.jpg']]\n","2022-04-17 18:18:46.232 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n","2022-04-17 18:18:53.034 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n","2022-04-17 18:18:56.630 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n","2022-04-17 18:19:10.663 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n","2022-04-17 18:19:14.416 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n","2022-04-17 18:19:17.988 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n","2022-04-17 18:19:21.236 | WARNING  | src.loftr.utils.supervision:spvs_coarse:93 - No groundtruth coarse match found for: [['../input/image-matching-challenge-2022/train/british_museum/images/73839172_5084383337.jpg'], ['../input/image-matching-challenge-2022/train/british_museum/images/71902171_5360301587.jpg']]\n","2022-04-17 18:19:21.472 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n","2022-04-17 18:19:36.172 | WARNING  | src.loftr.utils.supervision:spvs_coarse:93 - No groundtruth coarse match found for: [['../input/image-matching-challenge-2022/train/british_museum/images/73748105_4531531922.jpg'], ['../input/image-matching-challenge-2022/train/british_museum/images/72728072_3851668437.jpg']]\n","2022-04-17 18:19:36.407 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n","2022-04-17 18:19:51.061 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n","2022-04-17 18:20:02.073 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n","2022-04-17 18:20:09.595 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n","2022-04-17 18:20:13.209 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n","2022-04-17 18:20:28.474 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n","2022-04-17 18:20:32.310 | WARNING  | src.loftr.utils.supervision:spvs_coarse:93 - No groundtruth coarse match found for: [['../input/image-matching-challenge-2022/train/british_museum/images/18486676_4996206525.jpg'], ['../input/image-matching-challenge-2022/train/british_museum/images/12797227_4382766788.jpg']]\n","2022-04-17 18:20:32.548 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n","2022-04-17 18:20:36.593 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n","2022-04-17 18:20:55.907 | WARNING  | src.loftr.utils.supervision:spvs_coarse:93 - No groundtruth coarse match found for: [['../input/image-matching-challenge-2022/train/british_museum/images/42803655_6429621523.jpg'], ['../input/image-matching-challenge-2022/train/british_museum/images/03576546_367645446.jpg']]\n","2022-04-17 18:20:56.136 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n","2022-04-17 18:21:04.212 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n","2022-04-17 18:21:08.318 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n","2022-04-17 18:21:20.028 | WARNING  | src.loftr.utils.supervision:spvs_coarse:93 - No groundtruth coarse match found for: [['../input/image-matching-challenge-2022/train/british_museum/images/51869583_2554605419.jpg'], ['../input/image-matching-challenge-2022/train/british_museum/images/39461890_106560712.jpg']]\n","2022-04-17 18:21:20.264 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n","2022-04-17 18:21:24.086 | WARNING  | src.loftr.utils.supervision:spvs_coarse:93 - No groundtruth coarse match found for: [['../input/image-matching-challenge-2022/train/british_museum/images/51869583_2554605419.jpg'], ['../input/image-matching-challenge-2022/train/british_museum/images/14501930_447150094.jpg']]\n","2022-04-17 18:21:24.322 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"171d07b300d34c308c2ab82b7b347ce4","version_major":2,"version_minor":0},"text/plain":["Validation: 0it [00:00, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["2022-04-17 18:21:42.050 | INFO     | src.utils.metrics:aggregate_metrics:182 - Aggregating metrics over 1 unique items...\n","2022-04-17 18:22:11.721 | WARNING  | src.loftr.utils.supervision:spvs_coarse:93 - No groundtruth coarse match found for: [['../input/image-matching-challenge-2022/train/british_museum/images/94345807_4553191473.jpg'], ['../input/image-matching-challenge-2022/train/british_museum/images/84932226_4352179060.jpg']]\n","2022-04-17 18:22:11.952 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n","2022-04-17 18:22:15.874 | WARNING  | src.loftr.utils.supervision:spvs_coarse:93 - No groundtruth coarse match found for: [['../input/image-matching-challenge-2022/train/british_museum/images/93658023_4980549800.jpg'], ['../input/image-matching-challenge-2022/train/british_museum/images/92199010_423632152.jpg']]\n","2022-04-17 18:22:16.105 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n","2022-04-17 18:22:20.079 | WARNING  | src.loftr.utils.supervision:spvs_coarse:93 - No groundtruth coarse match found for: [['../input/image-matching-challenge-2022/train/british_museum/images/93658023_4980549800.jpg'], ['../input/image-matching-challenge-2022/train/british_museum/images/78242267_4404579754.jpg']]\n","2022-04-17 18:22:20.314 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n","2022-04-17 18:23:00.352 | WARNING  | src.loftr.utils.supervision:spvs_coarse:93 - No groundtruth coarse match found for: [['../input/image-matching-challenge-2022/train/british_museum/images/93658023_4980549800.jpg'], ['../input/image-matching-challenge-2022/train/british_museum/images/57504314_2114264842.jpg']]\n","2022-04-17 18:23:00.585 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n","2022-04-17 18:23:05.110 | WARNING  | src.loftr.utils.supervision:spvs_coarse:93 - No groundtruth coarse match found for: [['../input/image-matching-challenge-2022/train/british_museum/images/93658023_4980549800.jpg'], ['../input/image-matching-challenge-2022/train/british_museum/images/59326840_8032269061.jpg']]\n","2022-04-17 18:23:05.341 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n","2022-04-17 18:23:09.488 | WARNING  | src.loftr.utils.supervision:spvs_coarse:93 - No groundtruth coarse match found for: [['../input/image-matching-challenge-2022/train/british_museum/images/93658023_4980549800.jpg'], ['../input/image-matching-challenge-2022/train/british_museum/images/62553151_839585618.jpg']]\n","2022-04-17 18:23:09.720 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n","2022-04-17 18:23:13.949 | WARNING  | src.loftr.utils.supervision:spvs_coarse:93 - No groundtruth coarse match found for: [['../input/image-matching-challenge-2022/train/british_museum/images/92942151_2078102935.jpg'], ['../input/image-matching-challenge-2022/train/british_museum/images/01858319_78150445.jpg']]\n","2022-04-17 18:23:14.183 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n","2022-04-17 18:23:18.620 | WARNING  | src.loftr.utils.supervision:spvs_coarse:93 - No groundtruth coarse match found for: [['../input/image-matching-challenge-2022/train/british_museum/images/92199010_423632152.jpg'], ['../input/image-matching-challenge-2022/train/british_museum/images/83025239_9530039386.jpg']]\n","2022-04-17 18:23:18.856 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n","2022-04-17 18:23:23.039 | WARNING  | src.loftr.utils.supervision:spvs_coarse:93 - No groundtruth coarse match found for: [['../input/image-matching-challenge-2022/train/british_museum/images/92199010_423632152.jpg'], ['../input/image-matching-challenge-2022/train/british_museum/images/75879177_2453112255.jpg']]\n","2022-04-17 18:23:23.271 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n","2022-04-17 18:23:32.222 | WARNING  | src.loftr.utils.supervision:spvs_coarse:93 - No groundtruth coarse match found for: [['../input/image-matching-challenge-2022/train/british_museum/images/92199010_423632152.jpg'], ['../input/image-matching-challenge-2022/train/british_museum/images/51869583_2554605419.jpg']]\n","2022-04-17 18:23:32.457 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n","2022-04-17 18:23:37.017 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n","2022-04-17 18:23:46.052 | WARNING  | src.loftr.utils.supervision:spvs_coarse:93 - No groundtruth coarse match found for: [['../input/image-matching-challenge-2022/train/british_museum/images/90250998_7086081737.jpg'], ['../input/image-matching-challenge-2022/train/british_museum/images/39461890_106560712.jpg']]\n","2022-04-17 18:23:46.284 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n","2022-04-17 18:23:55.471 | WARNING  | src.loftr.utils.supervision:spvs_coarse:93 - No groundtruth coarse match found for: [['../input/image-matching-challenge-2022/train/british_museum/images/90250998_7086081737.jpg'], ['../input/image-matching-challenge-2022/train/british_museum/images/51869583_2554605419.jpg']]\n","2022-04-17 18:23:55.704 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n","2022-04-17 18:24:09.391 | WARNING  | src.loftr.utils.supervision:spvs_coarse:93 - No groundtruth coarse match found for: [['../input/image-matching-challenge-2022/train/british_museum/images/88500284_27304784.jpg'], ['../input/image-matching-challenge-2022/train/british_museum/images/72728072_3851668437.jpg']]\n","2022-04-17 18:24:09.623 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n","2022-04-17 18:24:18.865 | WARNING  | src.loftr.utils.supervision:spvs_coarse:93 - No groundtruth coarse match found for: [['../input/image-matching-challenge-2022/train/british_museum/images/84932226_4352179060.jpg'], ['../input/image-matching-challenge-2022/train/british_museum/images/06793539_251350697.jpg']]\n","2022-04-17 18:24:19.097 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n","2022-04-17 18:24:23.803 | WARNING  | src.loftr.utils.supervision:spvs_coarse:93 - No groundtruth coarse match found for: [['../input/image-matching-challenge-2022/train/british_museum/images/84932226_4352179060.jpg'], ['../input/image-matching-challenge-2022/train/british_museum/images/14501930_447150094.jpg']]\n","2022-04-17 18:24:24.035 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n","2022-04-17 18:24:28.625 | WARNING  | src.loftr.utils.supervision:spvs_coarse:93 - No groundtruth coarse match found for: [['../input/image-matching-challenge-2022/train/british_museum/images/84932226_4352179060.jpg'], ['../input/image-matching-challenge-2022/train/british_museum/images/51869583_2554605419.jpg']]\n","2022-04-17 18:24:28.857 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n","2022-04-17 18:24:33.714 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n","2022-04-17 18:24:38.189 | WARNING  | src.loftr.utils.supervision:spvs_coarse:93 - No groundtruth coarse match found for: [['../input/image-matching-challenge-2022/train/british_museum/images/78242267_4404579754.jpg'], ['../input/image-matching-challenge-2022/train/british_museum/images/69960354_6519615529.jpg']]\n","2022-04-17 18:24:38.419 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n","2022-04-17 18:24:43.071 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n","2022-04-17 18:24:47.923 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n","2022-04-17 18:24:52.551 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n","2022-04-17 18:24:57.647 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n","2022-04-17 18:25:02.173 | WARNING  | src.loftr.utils.supervision:spvs_coarse:93 - No groundtruth coarse match found for: [['../input/image-matching-challenge-2022/train/british_museum/images/77723525_5227836172.jpg'], ['../input/image-matching-challenge-2022/train/british_museum/images/75879177_2453112255.jpg']]\n","2022-04-17 18:25:02.406 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n","2022-04-17 18:25:36.586 | WARNING  | src.loftr.utils.supervision:spvs_coarse:93 - No groundtruth coarse match found for: [['../input/image-matching-challenge-2022/train/british_museum/images/77723525_5227836172.jpg'], ['../input/image-matching-challenge-2022/train/british_museum/images/57504314_2114264842.jpg']]\n","2022-04-17 18:25:36.819 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n","2022-04-17 18:25:46.599 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n","2022-04-17 18:25:51.633 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n","2022-04-17 18:25:56.483 | WARNING  | src.loftr.utils.supervision:spvs_coarse:93 - No groundtruth coarse match found for: [['../input/image-matching-challenge-2022/train/british_museum/images/75879177_2453112255.jpg'], ['../input/image-matching-challenge-2022/train/british_museum/images/69960354_6519615529.jpg']]\n","2022-04-17 18:25:56.714 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n","2022-04-17 18:26:06.919 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n","2022-04-17 18:26:11.989 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n","2022-04-17 18:26:32.689 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n","2022-04-17 18:26:38.133 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n","2022-04-17 18:26:43.281 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n","2022-04-17 18:26:48.154 | WARNING  | src.loftr.utils.supervision:spvs_coarse:93 - No groundtruth coarse match found for: [['../input/image-matching-challenge-2022/train/british_museum/images/73839172_5084383337.jpg'], ['../input/image-matching-challenge-2022/train/british_museum/images/71902171_5360301587.jpg']]\n","2022-04-17 18:26:48.390 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n","2022-04-17 18:27:09.462 | WARNING  | src.loftr.utils.supervision:spvs_coarse:93 - No groundtruth coarse match found for: [['../input/image-matching-challenge-2022/train/british_museum/images/73748105_4531531922.jpg'], ['../input/image-matching-challenge-2022/train/british_museum/images/72728072_3851668437.jpg']]\n","2022-04-17 18:27:09.696 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n","2022-04-17 18:27:30.840 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n","2022-04-17 18:27:46.878 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n","2022-04-17 18:27:57.494 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n","2022-04-17 18:28:02.835 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n","2022-04-17 18:28:24.782 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n","2022-04-17 18:28:29.926 | WARNING  | src.loftr.utils.supervision:spvs_coarse:93 - No groundtruth coarse match found for: [['../input/image-matching-challenge-2022/train/british_museum/images/18486676_4996206525.jpg'], ['../input/image-matching-challenge-2022/train/british_museum/images/12797227_4382766788.jpg']]\n","2022-04-17 18:28:30.166 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n","2022-04-17 18:28:35.849 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n","2022-04-17 18:29:03.411 | WARNING  | src.loftr.utils.supervision:spvs_coarse:93 - No groundtruth coarse match found for: [['../input/image-matching-challenge-2022/train/british_museum/images/42803655_6429621523.jpg'], ['../input/image-matching-challenge-2022/train/british_museum/images/03576546_367645446.jpg']]\n","2022-04-17 18:29:03.640 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n","2022-04-17 18:29:15.034 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n","2022-04-17 18:29:20.763 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n","2022-04-17 18:29:37.266 | WARNING  | src.loftr.utils.supervision:spvs_coarse:93 - No groundtruth coarse match found for: [['../input/image-matching-challenge-2022/train/british_museum/images/51869583_2554605419.jpg'], ['../input/image-matching-challenge-2022/train/british_museum/images/39461890_106560712.jpg']]\n","2022-04-17 18:29:37.502 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n","2022-04-17 18:29:43.303 | WARNING  | src.loftr.utils.supervision:spvs_coarse:93 - No groundtruth coarse match found for: [['../input/image-matching-challenge-2022/train/british_museum/images/51869583_2554605419.jpg'], ['../input/image-matching-challenge-2022/train/british_museum/images/14501930_447150094.jpg']]\n","2022-04-17 18:29:43.539 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ee528cb255ac4ba5b4f78091f57c17a6","version_major":2,"version_minor":0},"text/plain":["Validation: 0it [00:00, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["2022-04-17 18:30:08.194 | INFO     | src.utils.metrics:aggregate_metrics:182 - Aggregating metrics over 1 unique items...\n","2022-04-17 18:30:50.179 | WARNING  | src.loftr.utils.supervision:spvs_coarse:93 - No groundtruth coarse match found for: [['../input/image-matching-challenge-2022/train/british_museum/images/94345807_4553191473.jpg'], ['../input/image-matching-challenge-2022/train/british_museum/images/84932226_4352179060.jpg']]\n","2022-04-17 18:30:50.411 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n","2022-04-17 18:30:55.927 | WARNING  | src.loftr.utils.supervision:spvs_coarse:93 - No groundtruth coarse match found for: [['../input/image-matching-challenge-2022/train/british_museum/images/93658023_4980549800.jpg'], ['../input/image-matching-challenge-2022/train/british_museum/images/92199010_423632152.jpg']]\n","2022-04-17 18:30:56.158 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n","2022-04-17 18:31:01.740 | WARNING  | src.loftr.utils.supervision:spvs_coarse:93 - No groundtruth coarse match found for: [['../input/image-matching-challenge-2022/train/british_museum/images/93658023_4980549800.jpg'], ['../input/image-matching-challenge-2022/train/british_museum/images/78242267_4404579754.jpg']]\n","2022-04-17 18:31:01.972 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n","2022-04-17 18:31:56.286 | WARNING  | src.loftr.utils.supervision:spvs_coarse:93 - No groundtruth coarse match found for: [['../input/image-matching-challenge-2022/train/british_museum/images/93658023_4980549800.jpg'], ['../input/image-matching-challenge-2022/train/british_museum/images/57504314_2114264842.jpg']]\n","2022-04-17 18:31:56.515 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n","2022-04-17 18:32:02.461 | WARNING  | src.loftr.utils.supervision:spvs_coarse:93 - No groundtruth coarse match found for: [['../input/image-matching-challenge-2022/train/british_museum/images/93658023_4980549800.jpg'], ['../input/image-matching-challenge-2022/train/british_museum/images/59326840_8032269061.jpg']]\n","2022-04-17 18:32:02.692 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n","2022-04-17 18:32:08.666 | WARNING  | src.loftr.utils.supervision:spvs_coarse:93 - No groundtruth coarse match found for: [['../input/image-matching-challenge-2022/train/british_museum/images/93658023_4980549800.jpg'], ['../input/image-matching-challenge-2022/train/british_museum/images/62553151_839585618.jpg']]\n","2022-04-17 18:32:08.898 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n","2022-04-17 18:32:14.805 | WARNING  | src.loftr.utils.supervision:spvs_coarse:93 - No groundtruth coarse match found for: [['../input/image-matching-challenge-2022/train/british_museum/images/92942151_2078102935.jpg'], ['../input/image-matching-challenge-2022/train/british_museum/images/01858319_78150445.jpg']]\n","2022-04-17 18:32:15.040 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n","2022-04-17 18:32:20.909 | WARNING  | src.loftr.utils.supervision:spvs_coarse:93 - No groundtruth coarse match found for: [['../input/image-matching-challenge-2022/train/british_museum/images/92199010_423632152.jpg'], ['../input/image-matching-challenge-2022/train/british_museum/images/83025239_9530039386.jpg']]\n","2022-04-17 18:32:21.143 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n","2022-04-17 18:32:27.044 | WARNING  | src.loftr.utils.supervision:spvs_coarse:93 - No groundtruth coarse match found for: [['../input/image-matching-challenge-2022/train/british_museum/images/92199010_423632152.jpg'], ['../input/image-matching-challenge-2022/train/british_museum/images/75879177_2453112255.jpg']]\n","2022-04-17 18:32:27.321 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n","2022-04-17 18:32:39.480 | WARNING  | src.loftr.utils.supervision:spvs_coarse:93 - No groundtruth coarse match found for: [['../input/image-matching-challenge-2022/train/british_museum/images/92199010_423632152.jpg'], ['../input/image-matching-challenge-2022/train/british_museum/images/51869583_2554605419.jpg']]\n","2022-04-17 18:32:39.716 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n","2022-04-17 18:32:45.877 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n","2022-04-17 18:32:57.971 | WARNING  | src.loftr.utils.supervision:spvs_coarse:93 - No groundtruth coarse match found for: [['../input/image-matching-challenge-2022/train/british_museum/images/90250998_7086081737.jpg'], ['../input/image-matching-challenge-2022/train/british_museum/images/39461890_106560712.jpg']]\n","2022-04-17 18:32:58.202 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n","2022-04-17 18:33:10.557 | WARNING  | src.loftr.utils.supervision:spvs_coarse:93 - No groundtruth coarse match found for: [['../input/image-matching-challenge-2022/train/british_museum/images/90250998_7086081737.jpg'], ['../input/image-matching-challenge-2022/train/british_museum/images/51869583_2554605419.jpg']]\n","2022-04-17 18:33:10.789 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n","2022-04-17 18:33:29.258 | WARNING  | src.loftr.utils.supervision:spvs_coarse:93 - No groundtruth coarse match found for: [['../input/image-matching-challenge-2022/train/british_museum/images/88500284_27304784.jpg'], ['../input/image-matching-challenge-2022/train/british_museum/images/72728072_3851668437.jpg']]\n","2022-04-17 18:33:29.495 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n","2022-04-17 18:33:42.199 | WARNING  | src.loftr.utils.supervision:spvs_coarse:93 - No groundtruth coarse match found for: [['../input/image-matching-challenge-2022/train/british_museum/images/84932226_4352179060.jpg'], ['../input/image-matching-challenge-2022/train/british_museum/images/06793539_251350697.jpg']]\n","2022-04-17 18:33:42.440 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n","2022-04-17 18:33:48.633 | WARNING  | src.loftr.utils.supervision:spvs_coarse:93 - No groundtruth coarse match found for: [['../input/image-matching-challenge-2022/train/british_museum/images/84932226_4352179060.jpg'], ['../input/image-matching-challenge-2022/train/british_museum/images/14501930_447150094.jpg']]\n","2022-04-17 18:33:48.866 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n","2022-04-17 18:33:54.988 | WARNING  | src.loftr.utils.supervision:spvs_coarse:93 - No groundtruth coarse match found for: [['../input/image-matching-challenge-2022/train/british_museum/images/84932226_4352179060.jpg'], ['../input/image-matching-challenge-2022/train/british_museum/images/51869583_2554605419.jpg']]\n","2022-04-17 18:33:55.221 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n","2022-04-17 18:34:01.501 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n","2022-04-17 18:34:08.042 | WARNING  | src.loftr.utils.supervision:spvs_coarse:93 - No groundtruth coarse match found for: [['../input/image-matching-challenge-2022/train/british_museum/images/78242267_4404579754.jpg'], ['../input/image-matching-challenge-2022/train/british_museum/images/69960354_6519615529.jpg']]\n","2022-04-17 18:34:08.273 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n","2022-04-17 18:34:14.523 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n","2022-04-17 18:34:20.963 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n","2022-04-17 18:34:27.234 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n","2022-04-17 18:34:33.628 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n","2022-04-17 18:34:40.108 | WARNING  | src.loftr.utils.supervision:spvs_coarse:93 - No groundtruth coarse match found for: [['../input/image-matching-challenge-2022/train/british_museum/images/77723525_5227836172.jpg'], ['../input/image-matching-challenge-2022/train/british_museum/images/75879177_2453112255.jpg']]\n","2022-04-17 18:34:40.349 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n","2022-04-17 18:35:25.484 | WARNING  | src.loftr.utils.supervision:spvs_coarse:93 - No groundtruth coarse match found for: [['../input/image-matching-challenge-2022/train/british_museum/images/77723525_5227836172.jpg'], ['../input/image-matching-challenge-2022/train/british_museum/images/57504314_2114264842.jpg']]\n","2022-04-17 18:35:25.717 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n","2022-04-17 18:35:38.894 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n","2022-04-17 18:35:45.549 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n","2022-04-17 18:35:52.228 | WARNING  | src.loftr.utils.supervision:spvs_coarse:93 - No groundtruth coarse match found for: [['../input/image-matching-challenge-2022/train/british_museum/images/75879177_2453112255.jpg'], ['../input/image-matching-challenge-2022/train/british_museum/images/69960354_6519615529.jpg']]\n","2022-04-17 18:35:52.461 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n","2022-04-17 18:36:05.530 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n","2022-04-17 18:36:12.218 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n","2022-04-17 18:36:39.322 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n","2022-04-17 18:36:46.150 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n","2022-04-17 18:36:53.283 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n","2022-04-17 18:36:59.740 | WARNING  | src.loftr.utils.supervision:spvs_coarse:93 - No groundtruth coarse match found for: [['../input/image-matching-challenge-2022/train/british_museum/images/73839172_5084383337.jpg'], ['../input/image-matching-challenge-2022/train/british_museum/images/71902171_5360301587.jpg']]\n","2022-04-17 18:36:59.976 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n","2022-04-17 18:37:27.494 | WARNING  | src.loftr.utils.supervision:spvs_coarse:93 - No groundtruth coarse match found for: [['../input/image-matching-challenge-2022/train/british_museum/images/73748105_4531531922.jpg'], ['../input/image-matching-challenge-2022/train/british_museum/images/72728072_3851668437.jpg']]\n","2022-04-17 18:37:27.729 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n","2022-04-17 18:37:55.483 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n","2022-04-17 18:38:16.308 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n","2022-04-17 18:38:30.410 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n","2022-04-17 18:38:37.318 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n","2022-04-17 18:39:05.577 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n","2022-04-17 18:39:12.425 | WARNING  | src.loftr.utils.supervision:spvs_coarse:93 - No groundtruth coarse match found for: [['../input/image-matching-challenge-2022/train/british_museum/images/18486676_4996206525.jpg'], ['../input/image-matching-challenge-2022/train/british_museum/images/12797227_4382766788.jpg']]\n","2022-04-17 18:39:12.664 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n","2022-04-17 18:39:19.860 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n","2022-04-17 18:39:55.598 | WARNING  | src.loftr.utils.supervision:spvs_coarse:93 - No groundtruth coarse match found for: [['../input/image-matching-challenge-2022/train/british_museum/images/42803655_6429621523.jpg'], ['../input/image-matching-challenge-2022/train/british_museum/images/03576546_367645446.jpg']]\n","2022-04-17 18:39:55.828 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n","2022-04-17 18:40:10.677 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n","2022-04-17 18:40:17.862 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n","2022-04-17 18:40:39.299 | WARNING  | src.loftr.utils.supervision:spvs_coarse:93 - No groundtruth coarse match found for: [['../input/image-matching-challenge-2022/train/british_museum/images/51869583_2554605419.jpg'], ['../input/image-matching-challenge-2022/train/british_museum/images/39461890_106560712.jpg']]\n","2022-04-17 18:40:39.534 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n","2022-04-17 18:40:47.046 | WARNING  | src.loftr.utils.supervision:spvs_coarse:93 - No groundtruth coarse match found for: [['../input/image-matching-challenge-2022/train/british_museum/images/51869583_2554605419.jpg'], ['../input/image-matching-challenge-2022/train/british_museum/images/14501930_447150094.jpg']]\n","2022-04-17 18:40:47.291 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ac4f19dccac04db8bbe7a440bb2a23b5","version_major":2,"version_minor":0},"text/plain":["Validation: 0it [00:00, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["2022-04-17 18:41:19.430 | INFO     | src.utils.metrics:aggregate_metrics:182 - Aggregating metrics over 1 unique items...\n","2022-04-17 18:42:12.968 | WARNING  | src.loftr.utils.supervision:spvs_coarse:93 - No groundtruth coarse match found for: [['../input/image-matching-challenge-2022/train/british_museum/images/94345807_4553191473.jpg'], ['../input/image-matching-challenge-2022/train/british_museum/images/84932226_4352179060.jpg']]\n","2022-04-17 18:42:13.199 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n","2022-04-17 18:42:20.588 | WARNING  | src.loftr.utils.supervision:spvs_coarse:93 - No groundtruth coarse match found for: [['../input/image-matching-challenge-2022/train/british_museum/images/93658023_4980549800.jpg'], ['../input/image-matching-challenge-2022/train/british_museum/images/92199010_423632152.jpg']]\n","2022-04-17 18:42:20.821 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n","2022-04-17 18:42:28.411 | WARNING  | src.loftr.utils.supervision:spvs_coarse:93 - No groundtruth coarse match found for: [['../input/image-matching-challenge-2022/train/british_museum/images/93658023_4980549800.jpg'], ['../input/image-matching-challenge-2022/train/british_museum/images/78242267_4404579754.jpg']]\n","2022-04-17 18:42:28.645 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n","2022-04-17 18:43:37.851 | WARNING  | src.loftr.utils.supervision:spvs_coarse:93 - No groundtruth coarse match found for: [['../input/image-matching-challenge-2022/train/british_museum/images/93658023_4980549800.jpg'], ['../input/image-matching-challenge-2022/train/british_museum/images/57504314_2114264842.jpg']]\n","2022-04-17 18:43:38.085 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n","2022-04-17 18:43:45.689 | WARNING  | src.loftr.utils.supervision:spvs_coarse:93 - No groundtruth coarse match found for: [['../input/image-matching-challenge-2022/train/british_museum/images/93658023_4980549800.jpg'], ['../input/image-matching-challenge-2022/train/british_museum/images/59326840_8032269061.jpg']]\n","2022-04-17 18:43:45.921 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n","2022-04-17 18:43:53.469 | WARNING  | src.loftr.utils.supervision:spvs_coarse:93 - No groundtruth coarse match found for: [['../input/image-matching-challenge-2022/train/british_museum/images/93658023_4980549800.jpg'], ['../input/image-matching-challenge-2022/train/british_museum/images/62553151_839585618.jpg']]\n","2022-04-17 18:43:53.702 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n","2022-04-17 18:44:01.518 | WARNING  | src.loftr.utils.supervision:spvs_coarse:93 - No groundtruth coarse match found for: [['../input/image-matching-challenge-2022/train/british_museum/images/92942151_2078102935.jpg'], ['../input/image-matching-challenge-2022/train/british_museum/images/01858319_78150445.jpg']]\n","2022-04-17 18:44:01.753 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n","2022-04-17 18:44:09.147 | WARNING  | src.loftr.utils.supervision:spvs_coarse:93 - No groundtruth coarse match found for: [['../input/image-matching-challenge-2022/train/british_museum/images/92199010_423632152.jpg'], ['../input/image-matching-challenge-2022/train/british_museum/images/83025239_9530039386.jpg']]\n","2022-04-17 18:44:09.388 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n","2022-04-17 18:44:16.896 | WARNING  | src.loftr.utils.supervision:spvs_coarse:93 - No groundtruth coarse match found for: [['../input/image-matching-challenge-2022/train/british_museum/images/92199010_423632152.jpg'], ['../input/image-matching-challenge-2022/train/british_museum/images/75879177_2453112255.jpg']]\n","2022-04-17 18:44:17.129 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n","2022-04-17 18:44:33.168 | WARNING  | src.loftr.utils.supervision:spvs_coarse:93 - No groundtruth coarse match found for: [['../input/image-matching-challenge-2022/train/british_museum/images/92199010_423632152.jpg'], ['../input/image-matching-challenge-2022/train/british_museum/images/51869583_2554605419.jpg']]\n","2022-04-17 18:44:33.405 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n","2022-04-17 18:44:41.180 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n","2022-04-17 18:44:56.766 | WARNING  | src.loftr.utils.supervision:spvs_coarse:93 - No groundtruth coarse match found for: [['../input/image-matching-challenge-2022/train/british_museum/images/90250998_7086081737.jpg'], ['../input/image-matching-challenge-2022/train/british_museum/images/39461890_106560712.jpg']]\n","2022-04-17 18:44:56.999 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n","2022-04-17 18:45:12.639 | WARNING  | src.loftr.utils.supervision:spvs_coarse:93 - No groundtruth coarse match found for: [['../input/image-matching-challenge-2022/train/british_museum/images/90250998_7086081737.jpg'], ['../input/image-matching-challenge-2022/train/british_museum/images/51869583_2554605419.jpg']]\n","2022-04-17 18:45:12.872 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n","2022-04-17 18:45:36.290 | WARNING  | src.loftr.utils.supervision:spvs_coarse:93 - No groundtruth coarse match found for: [['../input/image-matching-challenge-2022/train/british_museum/images/88500284_27304784.jpg'], ['../input/image-matching-challenge-2022/train/british_museum/images/72728072_3851668437.jpg']]\n","2022-04-17 18:45:36.526 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n","2022-04-17 18:45:52.908 | WARNING  | src.loftr.utils.supervision:spvs_coarse:93 - No groundtruth coarse match found for: [['../input/image-matching-challenge-2022/train/british_museum/images/84932226_4352179060.jpg'], ['../input/image-matching-challenge-2022/train/british_museum/images/06793539_251350697.jpg']]\n","2022-04-17 18:45:53.141 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n","2022-04-17 18:46:00.994 | WARNING  | src.loftr.utils.supervision:spvs_coarse:93 - No groundtruth coarse match found for: [['../input/image-matching-challenge-2022/train/british_museum/images/84932226_4352179060.jpg'], ['../input/image-matching-challenge-2022/train/british_museum/images/14501930_447150094.jpg']]\n","2022-04-17 18:46:01.227 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n","2022-04-17 18:46:08.839 | WARNING  | src.loftr.utils.supervision:spvs_coarse:93 - No groundtruth coarse match found for: [['../input/image-matching-challenge-2022/train/british_museum/images/84932226_4352179060.jpg'], ['../input/image-matching-challenge-2022/train/british_museum/images/51869583_2554605419.jpg']]\n","2022-04-17 18:46:09.071 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n","2022-04-17 18:46:17.470 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n","2022-04-17 18:46:25.262 | WARNING  | src.loftr.utils.supervision:spvs_coarse:93 - No groundtruth coarse match found for: [['../input/image-matching-challenge-2022/train/british_museum/images/78242267_4404579754.jpg'], ['../input/image-matching-challenge-2022/train/british_museum/images/69960354_6519615529.jpg']]\n","2022-04-17 18:46:25.494 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n","2022-04-17 18:46:33.425 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n","2022-04-17 18:46:41.299 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n","2022-04-17 18:46:49.330 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n","2022-04-17 18:46:57.468 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n","2022-04-17 18:47:05.141 | WARNING  | src.loftr.utils.supervision:spvs_coarse:93 - No groundtruth coarse match found for: [['../input/image-matching-challenge-2022/train/british_museum/images/77723525_5227836172.jpg'], ['../input/image-matching-challenge-2022/train/british_museum/images/75879177_2453112255.jpg']]\n","2022-04-17 18:47:05.378 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n","2022-04-17 18:48:03.131 | WARNING  | src.loftr.utils.supervision:spvs_coarse:93 - No groundtruth coarse match found for: [['../input/image-matching-challenge-2022/train/british_museum/images/77723525_5227836172.jpg'], ['../input/image-matching-challenge-2022/train/british_museum/images/57504314_2114264842.jpg']]\n","2022-04-17 18:48:03.364 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n","2022-04-17 18:48:19.624 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n","2022-04-17 18:48:28.192 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n","2022-04-17 18:48:36.432 | WARNING  | src.loftr.utils.supervision:spvs_coarse:93 - No groundtruth coarse match found for: [['../input/image-matching-challenge-2022/train/british_museum/images/75879177_2453112255.jpg'], ['../input/image-matching-challenge-2022/train/british_museum/images/69960354_6519615529.jpg']]\n","2022-04-17 18:48:36.665 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n","2022-04-17 18:48:53.014 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n","2022-04-17 18:49:01.557 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n","2022-04-17 18:49:34.919 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n","2022-04-17 18:49:43.399 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n","2022-04-17 18:49:51.974 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n","2022-04-17 18:50:00.053 | WARNING  | src.loftr.utils.supervision:spvs_coarse:93 - No groundtruth coarse match found for: [['../input/image-matching-challenge-2022/train/british_museum/images/73839172_5084383337.jpg'], ['../input/image-matching-challenge-2022/train/british_museum/images/71902171_5360301587.jpg']]\n","2022-04-17 18:50:00.289 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n","2022-04-17 18:50:34.838 | WARNING  | src.loftr.utils.supervision:spvs_coarse:93 - No groundtruth coarse match found for: [['../input/image-matching-challenge-2022/train/british_museum/images/73748105_4531531922.jpg'], ['../input/image-matching-challenge-2022/train/british_museum/images/72728072_3851668437.jpg']]\n","2022-04-17 18:50:35.094 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n","2022-04-17 18:51:09.242 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n","2022-04-17 18:51:34.646 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n","2022-04-17 18:51:51.898 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n","2022-04-17 18:52:00.315 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n","2022-04-17 18:52:35.178 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n","2022-04-17 18:52:43.763 | WARNING  | src.loftr.utils.supervision:spvs_coarse:93 - No groundtruth coarse match found for: [['../input/image-matching-challenge-2022/train/british_museum/images/18486676_4996206525.jpg'], ['../input/image-matching-challenge-2022/train/british_museum/images/12797227_4382766788.jpg']]\n","2022-04-17 18:52:44.008 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n","2022-04-17 18:52:52.920 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n","2022-04-17 18:53:36.819 | WARNING  | src.loftr.utils.supervision:spvs_coarse:93 - No groundtruth coarse match found for: [['../input/image-matching-challenge-2022/train/british_museum/images/42803655_6429621523.jpg'], ['../input/image-matching-challenge-2022/train/british_museum/images/03576546_367645446.jpg']]\n","2022-04-17 18:53:37.050 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n","2022-04-17 18:53:55.111 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n","2022-04-17 18:54:03.906 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n","2022-04-17 18:54:30.331 | WARNING  | src.loftr.utils.supervision:spvs_coarse:93 - No groundtruth coarse match found for: [['../input/image-matching-challenge-2022/train/british_museum/images/51869583_2554605419.jpg'], ['../input/image-matching-challenge-2022/train/british_museum/images/39461890_106560712.jpg']]\n","2022-04-17 18:54:30.567 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n","2022-04-17 18:54:39.328 | WARNING  | src.loftr.utils.supervision:spvs_coarse:93 - No groundtruth coarse match found for: [['../input/image-matching-challenge-2022/train/british_museum/images/51869583_2554605419.jpg'], ['../input/image-matching-challenge-2022/train/british_museum/images/14501930_447150094.jpg']]\n","2022-04-17 18:54:39.564 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"38520d177ad34b5bb51368c1420d9eac","version_major":2,"version_minor":0},"text/plain":["Validation: 0it [00:00, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["2022-04-17 18:55:18.163 | INFO     | src.utils.metrics:aggregate_metrics:182 - Aggregating metrics over 1 unique items...\n"]}],"source":["train()"]},{"cell_type":"code","execution_count":null,"id":"fa93eb67","metadata":{"execution":{"iopub.execute_input":"2022-04-17T18:55:23.211624Z","iopub.status.busy":"2022-04-17T18:55:23.211374Z","iopub.status.idle":"2022-04-17T18:55:23.216571Z","shell.execute_reply":"2022-04-17T18:55:23.215854Z"},"papermill":{"duration":0.122884,"end_time":"2022-04-17T18:55:23.219795","exception":false,"start_time":"2022-04-17T18:55:23.096911","status":"completed"},"tags":[],"id":"fa93eb67","outputId":"a385ef78-3800-4b49-f5f6-d49c41d8d52a"},"outputs":[{"name":"stdout","output_type":"stream","text":["[Errno 2] No such file or directory: 'checkpoints/'\n","/kaggle/working\n"]}],"source":["%cd checkpoints/"]},{"cell_type":"code","execution_count":null,"id":"c15b6390","metadata":{"execution":{"iopub.execute_input":"2022-04-17T18:55:23.447468Z","iopub.status.busy":"2022-04-17T18:55:23.446885Z","iopub.status.idle":"2022-04-17T18:55:24.329773Z","shell.execute_reply":"2022-04-17T18:55:24.328941Z"},"papermill":{"duration":0.998439,"end_time":"2022-04-17T18:55:24.331972","exception":false,"start_time":"2022-04-17T18:55:23.333533","status":"completed"},"tags":[],"id":"c15b6390","outputId":"64faf5d8-a747-4b82-97e1-689335907c28"},"outputs":[{"name":"stdout","output_type":"stream","text":["__notebook__.ipynb  \u001b[0m\u001b[01;34mlogs\u001b[0m/\r\n"]}],"source":["ls"]},{"cell_type":"code","execution_count":null,"id":"a518dca1","metadata":{"papermill":{"duration":0.112429,"end_time":"2022-04-17T18:55:24.558947","exception":false,"start_time":"2022-04-17T18:55:24.446518","status":"completed"},"tags":[],"id":"a518dca1"},"outputs":[],"source":[""]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.12"},"papermill":{"default_parameters":{},"duration":2459.730043,"end_time":"2022-04-17T18:55:27.596599","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2022-04-17T18:14:27.866556","version":"2.3.4"},"widgets":{"application/vnd.jupyter.widget-state+json":{}},"colab":{"name":"training-loftr.ipynb","provenance":[],"collapsed_sections":[]}},"nbformat":4,"nbformat_minor":5}