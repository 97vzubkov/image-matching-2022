{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c483cce2",
   "metadata": {
    "papermill": {
     "duration": 0.012399,
     "end_time": "2022-05-06T15:15:11.197836",
     "exception": false,
     "start_time": "2022-05-06T15:15:11.185437",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Tutorial: Creating a submission with GPU dependencies (DISK)\n",
    "\n",
    "This notebook shows you how to create and submit a submission with custom dependencies.\n",
    "\n",
    "First, follow the steps in [this notebook](https://www.kaggle.com/code/eduardtrulls/imc2022-dependencies/edit/run/91840821) and import the resulting \"dataset\" to this notebook. Your `input` folder should now contain `imc2022-dependencies` (see right pane).\n",
    "\n",
    "The test set for this competition is hidden, and you score your solution by submitting the notebook. First, run the notebook with internet access on (right pane) and `dry_run=True`. Then you can set `dry_run=False`, toggle internet off, and submit the notebook for scoring using the \"submit\" button on the right pane."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "32291878",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2022-05-06T15:15:11.227735Z",
     "iopub.status.busy": "2022-05-06T15:15:11.226600Z",
     "iopub.status.idle": "2022-05-06T15:15:11.230256Z",
     "shell.execute_reply": "2022-05-06T15:15:11.229733Z",
     "shell.execute_reply.started": "2022-05-06T15:12:02.448321Z"
    },
    "papermill": {
     "duration": 0.021985,
     "end_time": "2022-05-06T15:15:11.230388",
     "exception": false,
     "start_time": "2022-05-06T15:15:11.208403",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "dry_run = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "268ac4ff",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-06T15:15:11.262914Z",
     "iopub.status.busy": "2022-05-06T15:15:11.259973Z",
     "iopub.status.idle": "2022-05-06T15:17:21.551906Z",
     "shell.execute_reply": "2022-05-06T15:17:21.551407Z",
     "shell.execute_reply.started": "2022-05-06T15:12:02.465520Z"
    },
    "papermill": {
     "duration": 130.312892,
     "end_time": "2022-05-06T15:17:21.552056",
     "exception": false,
     "start_time": "2022-05-06T15:15:11.239164",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in links: /kaggle/input/imc2022-dependencies/wheels\r\n",
      "Processing /kaggle/input/imc2022-dependencies/wheels/torch_dimcheck-0.0.1-py3-none-any.whl\r\n",
      "Installing collected packages: torch-dimcheck\r\n",
      "Successfully installed torch-dimcheck-0.0.1\r\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\r\n",
      "Looking in links: /kaggle/input/imc2022-dependencies/wheels\r\n",
      "Processing /kaggle/input/imc2022-dependencies/wheels/torch_localize-0.1.0-py3-none-any.whl\r\n",
      "Installing collected packages: torch-localize\r\n",
      "Successfully installed torch-localize-0.1.0\r\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\r\n",
      "Looking in links: /kaggle/input/imc2022-dependencies/wheels\r\n",
      "Processing /kaggle/input/imc2022-dependencies/wheels/unets-0.1.0-py3-none-any.whl\r\n",
      "Installing collected packages: unets\r\n",
      "Successfully installed unets-0.1.0\r\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\r\n",
      "Looking in links: /kaggle/input/imc2022-dependencies/wheels\r\n",
      "Processing /kaggle/input/imc2022-dependencies/wheels/disk-0.1.0-py3-none-any.whl\r\n",
      "Requirement already satisfied: torch in /opt/conda/lib/python3.7/site-packages (from disk) (1.9.1)\r\n",
      "Requirement already satisfied: opencv-python in /opt/conda/lib/python3.7/site-packages (from disk) (4.5.4.60)\r\n",
      "Requirement already satisfied: pydegensac in /opt/conda/lib/python3.7/site-packages (from disk) (0.1.2)\r\n",
      "Requirement already satisfied: tensorflow in /opt/conda/lib/python3.7/site-packages (from disk) (2.6.2)\r\n",
      "Requirement already satisfied: imageio in /opt/conda/lib/python3.7/site-packages (from disk) (2.9.0)\r\n",
      "Requirement already satisfied: tensorboard in /opt/conda/lib/python3.7/site-packages (from disk) (2.6.0)\r\n",
      "Requirement already satisfied: h5py in /opt/conda/lib/python3.7/site-packages (from disk) (3.1.0)\r\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.7/site-packages (from disk) (4.62.3)\r\n",
      "Requirement already satisfied: cached-property in /opt/conda/lib/python3.7/site-packages (from h5py->disk) (1.5.2)\r\n",
      "Requirement already satisfied: numpy>=1.14.5 in /opt/conda/lib/python3.7/site-packages (from h5py->disk) (1.20.3)\r\n",
      "Requirement already satisfied: pillow in /opt/conda/lib/python3.7/site-packages (from imageio->disk) (8.2.0)\r\n",
      "Requirement already satisfied: protobuf>=3.6.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard->disk) (3.19.4)\r\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard->disk) (59.5.0)\r\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /opt/conda/lib/python3.7/site-packages (from tensorboard->disk) (0.4.6)\r\n",
      "Requirement already satisfied: grpcio>=1.24.3 in /opt/conda/lib/python3.7/site-packages (from tensorboard->disk) (1.43.0)\r\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /opt/conda/lib/python3.7/site-packages (from tensorboard->disk) (2.0.2)\r\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard->disk) (1.8.0)\r\n",
      "Requirement already satisfied: absl-py>=0.4 in /opt/conda/lib/python3.7/site-packages (from tensorboard->disk) (0.15.0)\r\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.7/site-packages (from tensorboard->disk) (3.3.6)\r\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in /opt/conda/lib/python3.7/site-packages (from tensorboard->disk) (1.35.0)\r\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard->disk) (2.26.0)\r\n",
      "Requirement already satisfied: wheel>=0.26 in /opt/conda/lib/python3.7/site-packages (from tensorboard->disk) (0.37.0)\r\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard->disk) (0.6.1)\r\n",
      "Processing /kaggle/input/imc2022-dependencies/wheels/tensorflow-2.8.0-cp37-cp37m-manylinux2010_x86_64.whl\r\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /opt/conda/lib/python3.7/site-packages (from tensorflow->disk) (0.2.0)\r\n",
      "Processing /kaggle/input/imc2022-dependencies/wheels/tensorboard-2.8.0-py3-none-any.whl\r\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow->disk) (1.13.3)\r\n",
      "Requirement already satisfied: flatbuffers>=1.12 in /opt/conda/lib/python3.7/site-packages (from tensorflow->disk) (1.12)\r\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.1 in /opt/conda/lib/python3.7/site-packages (from tensorflow->disk) (1.1.2)\r\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /opt/conda/lib/python3.7/site-packages (from tensorflow->disk) (3.3.0)\r\n",
      "Requirement already satisfied: gast>=0.2.1 in /opt/conda/lib/python3.7/site-packages (from tensorflow->disk) (0.4.0)\r\n",
      "Processing /kaggle/input/imc2022-dependencies/wheels/tensorflow_io_gcs_filesystem-0.24.0-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl\r\n",
      "Requirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow->disk) (1.16.0)\r\n",
      "Processing /kaggle/input/imc2022-dependencies/wheels/keras-2.8.0-py2.py3-none-any.whl\r\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow->disk) (1.6.3)\r\n",
      "Processing /kaggle/input/imc2022-dependencies/wheels/tf_estimator_nightly-2.8.0.dev2021122109-py2.py3-none-any.whl\r\n",
      "Processing /kaggle/input/imc2022-dependencies/wheels/libclang-13.0.0-py2.py3-none-manylinux1_x86_64.whl\r\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow->disk) (1.1.0)\r\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /opt/conda/lib/python3.7/site-packages (from tensorflow->disk) (4.1.1)\r\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard->disk) (4.8)\r\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard->disk) (4.2.4)\r\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard->disk) (0.2.7)\r\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.7/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard->disk) (1.3.0)\r\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /opt/conda/lib/python3.7/site-packages (from markdown>=2.6.8->tensorboard->disk) (4.11.3)\r\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard->disk) (2.0.9)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard->disk) (3.1)\r\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard->disk) (1.26.7)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard->disk) (2021.10.8)\r\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard->disk) (3.6.0)\r\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/lib/python3.7/site-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard->disk) (0.4.8)\r\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.7/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard->disk) (3.1.1)\r\n",
      "Installing collected packages: tf-estimator-nightly, tensorflow-io-gcs-filesystem, tensorboard, libclang, keras, tensorflow, disk\r\n",
      "  Attempting uninstall: tensorboard\r\n",
      "    Found existing installation: tensorboard 2.6.0\r\n",
      "    Uninstalling tensorboard-2.6.0:\r\n",
      "      Successfully uninstalled tensorboard-2.6.0\r\n",
      "  Attempting uninstall: keras\r\n",
      "    Found existing installation: keras 2.6.0\r\n",
      "    Uninstalling keras-2.6.0:\r\n",
      "      Successfully uninstalled keras-2.6.0\r\n",
      "  Attempting uninstall: tensorflow\r\n",
      "    Found existing installation: tensorflow 2.6.2\r\n",
      "    Uninstalling tensorflow-2.6.2:\r\n",
      "      Successfully uninstalled tensorflow-2.6.2\r\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "explainable-ai-sdk 1.3.2 requires xai-image-widget, which is not installed.\r\n",
      "tfx-bsl 1.5.0 requires absl-py<0.13,>=0.9, but you have absl-py 0.15.0 which is incompatible.\r\n",
      "tfx-bsl 1.5.0 requires numpy<1.20,>=1.16, but you have numpy 1.20.3 which is incompatible.\r\n",
      "tfx-bsl 1.5.0 requires pyarrow<6,>=1, but you have pyarrow 6.0.1 which is incompatible.\r\n",
      "tensorflow-transform 1.5.0 requires absl-py<0.13,>=0.9, but you have absl-py 0.15.0 which is incompatible.\r\n",
      "tensorflow-transform 1.5.0 requires numpy<1.20,>=1.16, but you have numpy 1.20.3 which is incompatible.\r\n",
      "tensorflow-transform 1.5.0 requires pyarrow<6,>=1, but you have pyarrow 6.0.1 which is incompatible.\r\n",
      "tensorflow-transform 1.5.0 requires tensorflow!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,<2.8,>=1.15.2, but you have tensorflow 2.8.0 which is incompatible.\r\n",
      "tensorflow-io 0.21.0 requires tensorflow<2.7.0,>=2.6.0, but you have tensorflow 2.8.0 which is incompatible.\r\n",
      "tensorflow-io 0.21.0 requires tensorflow-io-gcs-filesystem==0.21.0, but you have tensorflow-io-gcs-filesystem 0.24.0 which is incompatible.\u001b[0m\r\n",
      "Successfully installed disk-0.1.0 keras-2.8.0 libclang-13.0.0 tensorboard-2.8.0 tensorflow-2.8.0 tensorflow-io-gcs-filesystem-0.24.0 tf-estimator-nightly-2.8.0.dev2021122109\r\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\r\n",
      "Processing /kaggle/input/loftrkornia/LOFTR-kornia/kornia-0.6.4-py2.py3-none-any.whl\r\n",
      "Requirement already satisfied: torch>=1.8.1 in /opt/conda/lib/python3.7/site-packages (from kornia==0.6.4) (1.9.1)\r\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.7/site-packages (from kornia==0.6.4) (21.3)\r\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.7/site-packages (from torch>=1.8.1->kornia==0.6.4) (4.1.1)\r\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging->kornia==0.6.4) (3.0.6)\r\n",
      "Installing collected packages: kornia\r\n",
      "  Attempting uninstall: kornia\r\n",
      "    Found existing installation: kornia 0.5.8\r\n",
      "    Uninstalling kornia-0.5.8:\r\n",
      "      Successfully uninstalled kornia-0.5.8\r\n",
      "Successfully installed kornia-0.6.4\r\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\r\n",
      "Processing /kaggle/input/loftrkornia/LOFTR-kornia/kornia_moons-0.1.9-py3-none-any.whl\r\n",
      "Requirement already satisfied: kornia in /opt/conda/lib/python3.7/site-packages (from kornia-moons==0.1.9) (0.6.4)\r\n",
      "Requirement already satisfied: matplotlib in /opt/conda/lib/python3.7/site-packages (from kornia-moons==0.1.9) (3.5.1)\r\n",
      "Requirement already satisfied: torch in /opt/conda/lib/python3.7/site-packages (from kornia-moons==0.1.9) (1.9.1)\r\n",
      "Requirement already satisfied: opencv-python in /opt/conda/lib/python3.7/site-packages (from kornia-moons==0.1.9) (4.5.4.60)\r\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.7/site-packages (from kornia->kornia-moons==0.1.9) (21.3)\r\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.7/site-packages (from torch->kornia-moons==0.1.9) (4.1.1)\r\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.7/site-packages (from matplotlib->kornia-moons==0.1.9) (4.28.4)\r\n",
      "Requirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.7/site-packages (from matplotlib->kornia-moons==0.1.9) (8.2.0)\r\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib->kornia-moons==0.1.9) (1.3.2)\r\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.7/site-packages (from matplotlib->kornia-moons==0.1.9) (1.20.3)\r\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.7/site-packages (from matplotlib->kornia-moons==0.1.9) (0.11.0)\r\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.7/site-packages (from matplotlib->kornia-moons==0.1.9) (2.8.2)\r\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib->kornia-moons==0.1.9) (3.0.6)\r\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.7/site-packages (from python-dateutil>=2.7->matplotlib->kornia-moons==0.1.9) (1.16.0)\r\n",
      "Installing collected packages: kornia-moons\r\n",
      "Successfully installed kornia-moons-0.1.9\r\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "!pip install -f /kaggle/input/imc2022-dependencies/wheels --no-index torch_dimcheck\n",
    "!pip install -f /kaggle/input/imc2022-dependencies/wheels --no-index torch_localize\n",
    "!pip install -f /kaggle/input/imc2022-dependencies/wheels --no-index unets\n",
    "!pip install -f /kaggle/input/imc2022-dependencies/wheels --no-index disk\n",
    "\n",
    "!pip install ../input/loftrkornia/LOFTR-kornia/kornia-0.6.4-py2.py3-none-any.whl\n",
    "!pip install ../input/loftrkornia/LOFTR-kornia/kornia_moons-0.1.9-py3-none-any.whl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "03cabfce",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-06T15:17:21.605003Z",
     "iopub.status.busy": "2022-05-06T15:17:21.600595Z",
     "iopub.status.idle": "2022-05-06T15:17:24.162556Z",
     "shell.execute_reply": "2022-05-06T15:17:24.162007Z",
     "shell.execute_reply.started": "2022-05-06T15:13:28.720175Z"
    },
    "papermill": {
     "duration": 2.587529,
     "end_time": "2022-05-06T15:17:24.162714",
     "exception": false,
     "start_time": "2022-05-06T15:17:21.575185",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import imageio\n",
    "import numpy as np\n",
    "from disk import DISK, Features\n",
    "import torch\n",
    "import torch.nn.functional as TorchFunctional\n",
    "from torch.utils.data import DataLoader\n",
    "from torch_dimcheck import dimchecked\n",
    "from tqdm import tqdm\n",
    "import argparse\n",
    "from functools import partial\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "from glob import glob\n",
    "import csv\n",
    "import cv2\n",
    "import pydegensac\n",
    "\n",
    "import kornia\n",
    "import kornia.feature as kornia_feature\n",
    "from kornia_moons.feature import *\n",
    "import gc\n",
    "\n",
    "if not torch.cuda.is_available():\n",
    "    print('You may want to enable the GPU switch?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "255cf3e7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-06T15:17:24.233668Z",
     "iopub.status.busy": "2022-05-06T15:17:24.232858Z",
     "iopub.status.idle": "2022-05-06T15:17:24.264533Z",
     "shell.execute_reply": "2022-05-06T15:17:24.265656Z",
     "shell.execute_reply.started": "2022-05-06T15:13:29.766731Z"
    },
    "papermill": {
     "duration": 0.079925,
     "end_time": "2022-05-06T15:17:24.265874",
     "exception": false,
     "start_time": "2022-05-06T15:17:24.185949",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def FlattenMatrix(M, num_digits=8):\n",
    "    '''Convenience function to write CSV files.'''\n",
    "    \n",
    "    return ' '.join([f'{v:.{num_digits}e}' for v in M.flatten()])\n",
    "\n",
    "\n",
    "def BuildCompositeImage(im1, im2, axis=1, margin=0, background=1):\n",
    "    '''Convenience function to stack two images with different sizes.'''\n",
    "    \n",
    "    if background != 0 and background != 1:\n",
    "        background = 1\n",
    "    if axis != 0 and axis != 1:\n",
    "        raise RuntimeError('Axis must be 0 (vertical) or 1 (horizontal')\n",
    "\n",
    "    h1, w1, _ = im1.shape\n",
    "    h2, w2, _ = im2.shape\n",
    "\n",
    "    if axis == 1:\n",
    "        composite = np.zeros((max(h1, h2), w1 + w2 + margin, 3), dtype=np.uint8) + 255 * background\n",
    "        if h1 > h2:\n",
    "            voff1, voff2 = 0, (h1 - h2) // 2\n",
    "        else:\n",
    "            voff1, voff2 = (h2 - h1) // 2, 0\n",
    "        hoff1, hoff2 = 0, w1 + margin\n",
    "    else:\n",
    "        composite = np.zeros((h1 + h2 + margin, max(w1, w2), 3), dtype=np.uint8) + 255 * background\n",
    "        if w1 > w2:\n",
    "            hoff1, hoff2 = 0, (w1 - w2) // 2\n",
    "        else:\n",
    "            hoff1, hoff2 = (w2 - w1) // 2, 0\n",
    "        voff1, voff2 = 0, h1 + margin\n",
    "    composite[voff1:voff1 + h1, hoff1:hoff1 + w1, :] = im1\n",
    "    composite[voff2:voff2 + h2, hoff2:hoff2 + w2, :] = im2\n",
    "\n",
    "    return (composite, (voff1, voff2), (hoff1, hoff2))\n",
    "\n",
    "\n",
    "def DrawMatches(im1, im2, kp1, kp2, matches, axis=1, margin=0, background=0, linewidth=2):\n",
    "    '''Draw keypoints and matches.'''\n",
    "    \n",
    "    composite, v_offset, h_offset = BuildCompositeImage(im1, im2, axis, margin, background)\n",
    "\n",
    "    # Draw all keypoints.\n",
    "    for coord_a, coord_b in zip(kp1, kp2):\n",
    "        composite = cv2.drawMarker(composite, (int(coord_a[0] + h_offset[0]), int(coord_a[1] + v_offset[0])), color=(255, 0, 0), markerType=cv2.MARKER_CROSS, markerSize=5, thickness=1)\n",
    "        composite = cv2.drawMarker(composite, (int(coord_b[0] + h_offset[1]), int(coord_b[1] + v_offset[1])), color=(255, 0, 0), markerType=cv2.MARKER_CROSS, markerSize=5, thickness=1)\n",
    "    \n",
    "    # Draw matches, and highlight keypoints used in matches.\n",
    "    for idx_a, idx_b in matches:\n",
    "        composite = cv2.drawMarker(composite, (int(kp1[idx_a, 0] + h_offset[0]), int(kp1[idx_a, 1] + v_offset[0])), color=(0, 0, 255), markerType=cv2.MARKER_CROSS, markerSize=12, thickness=1)\n",
    "        composite = cv2.drawMarker(composite, (int(kp2[idx_b, 0] + h_offset[1]), int(kp2[idx_b, 1] + v_offset[1])), color=(0, 0, 255), markerType=cv2.MARKER_CROSS, markerSize=12, thickness=1)\n",
    "        composite = cv2.line(composite,\n",
    "                             tuple([int(kp1[idx_a][0] + h_offset[0]),\n",
    "                                   int(kp1[idx_a][1] + v_offset[0])]),\n",
    "                             tuple([int(kp2[idx_b][0] + h_offset[1]),\n",
    "                                   int(kp2[idx_b][1] + v_offset[1])]), color=(0, 0, 255), thickness=1)\n",
    "    \n",
    "    return composite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a10d98b4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-06T15:17:24.355759Z",
     "iopub.status.busy": "2022-05-06T15:17:24.354624Z",
     "iopub.status.idle": "2022-05-06T15:17:24.361824Z",
     "shell.execute_reply": "2022-05-06T15:17:24.362720Z",
     "shell.execute_reply.started": "2022-05-06T15:13:29.790026Z"
    },
    "papermill": {
     "duration": 0.054017,
     "end_time": "2022-05-06T15:17:24.362977",
     "exception": false,
     "start_time": "2022-05-06T15:17:24.308960",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Read the pairs file.\n",
    "\n",
    "src = '/kaggle/input/image-matching-challenge-2022/'\n",
    "\n",
    "test_samples = []\n",
    "with open(f'{src}/test.csv') as f:\n",
    "    reader = csv.reader(f, delimiter=',')\n",
    "    for i, row in enumerate(reader):\n",
    "        # Skip header.\n",
    "        if i == 0:\n",
    "            continue\n",
    "        test_samples += [row]\n",
    "\n",
    "if dry_run:\n",
    "    for sample in test_samples:\n",
    "        print(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2bac6287",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-06T15:17:24.467449Z",
     "iopub.status.busy": "2022-05-06T15:17:24.466440Z",
     "iopub.status.idle": "2022-05-06T15:17:35.363090Z",
     "shell.execute_reply": "2022-05-06T15:17:35.363897Z",
     "shell.execute_reply.started": "2022-05-06T15:13:29.803307Z"
    },
    "papermill": {
     "duration": 10.952009,
     "end_time": "2022-05-06T15:17:35.364075",
     "exception": false,
     "start_time": "2022-05-06T15:17:24.412066",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(desc_dim=128, detection_scores=False, f16=False, height=768, image_extension='png', mode='nms', model_path='/kaggle/input/imc2022-dependencies/pretrained/disk-depth.pth', n=1000, width=1024, window=9)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  cpuset_checked))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing \"/kaggle/input/image-matching-challenge-2022/test_images/1cf87530\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:05<00:00,  2.80s/it, n=1000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing \"/kaggle/input/image-matching-challenge-2022/test_images/6ceaefff\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00,  2.47it/s, n=1000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing \"/kaggle/input/image-matching-challenge-2022/test_images/d91db836\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00,  2.83it/s, n=1000]\n"
     ]
    }
   ],
   "source": [
    "# Pre-compute features. Code hastily copy-pasted with minor changes from:\n",
    "# https://github.com/cvlab-epfl/disk/blob/master/detect.py\n",
    "\n",
    "!rm -rf features\n",
    "\n",
    "class Image:\n",
    "    def __init__(self, bitmap: ['C', 'H', 'W'], fname: str, orig_shape=None):\n",
    "        self.bitmap     = bitmap\n",
    "        self.fname      = fname\n",
    "        if orig_shape is None:\n",
    "            self.orig_shape = self.bitmap.shape[1:]\n",
    "        else:\n",
    "            self.orig_shape = orig_shape\n",
    "\n",
    "    def resize_to(self, shape):\n",
    "        return Image(\n",
    "            self._pad(self._interpolate(self.bitmap, shape), shape),\n",
    "            self.fname,\n",
    "            orig_shape=self.bitmap.shape[1:],\n",
    "        )\n",
    "\n",
    "    @dimchecked\n",
    "    def to_image_coord(self, xys: [2, 'N']) -> ([2, 'N'], ['N']):\n",
    "        f, _size = self._compute_interpolation_size(self.bitmap.shape[1:])\n",
    "        scaled = xys / f\n",
    "\n",
    "        h, w = self.orig_shape\n",
    "        x, y = scaled\n",
    "\n",
    "        mask = (0 <= x) & (x < w) & (0 <= y) & (y < h)\n",
    "\n",
    "        return scaled, mask\n",
    "\n",
    "    def _compute_interpolation_size(self, shape):\n",
    "        x_factor = self.orig_shape[0] / shape[0]\n",
    "        y_factor = self.orig_shape[1] / shape[1]\n",
    "\n",
    "        f = 1 / max(x_factor, y_factor)\n",
    "\n",
    "        if x_factor > y_factor:\n",
    "            new_size = (shape[0], int(f * self.orig_shape[1]))\n",
    "        else:\n",
    "            new_size = (int(f * self.orig_shape[0]), shape[1])\n",
    "\n",
    "        return f, new_size\n",
    "\n",
    "    @dimchecked\n",
    "    def _interpolate(self, image: ['C', 'H', 'W'], shape) -> ['C', 'h', 'w']:\n",
    "        _f, size = self._compute_interpolation_size(shape)\n",
    "        return TorchFunctional.interpolate(\n",
    "            image.unsqueeze(0),\n",
    "            size=size,\n",
    "            mode='bilinear',\n",
    "            align_corners=False,\n",
    "        ).squeeze(0)\n",
    "    \n",
    "    @dimchecked\n",
    "    def _pad(self, image: ['C', 'H', 'W'], shape) -> ['C', 'h', 'w']:\n",
    "        x_pad = shape[0] - image.shape[1]\n",
    "        y_pad = shape[1] - image.shape[2]\n",
    "\n",
    "        if x_pad < 0 or y_pad < 0:\n",
    "            raise ValueError(\"Attempting to pad by negative value\")\n",
    "\n",
    "        return TorchFunctional.pad(image, (0, y_pad, 0, x_pad))\n",
    "\n",
    "    \n",
    "class SceneDataset:\n",
    "    def __init__(self, image_path, crop_size=(None, None)):\n",
    "        self.image_path = image_path\n",
    "        self.crop_size  = crop_size\n",
    "        self.names = [p for p in os.listdir(image_path) \\\n",
    "                      if p.endswith(args.image_extension)]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.names)\n",
    "\n",
    "    def __getitem__(self, ix):\n",
    "        name   = self.names[ix]\n",
    "        path   = os.path.join(self.image_path, name) \n",
    "        img    = np.ascontiguousarray(imageio.imread(path))\n",
    "        tensor = torch.from_numpy(img).to(torch.float32)\n",
    "\n",
    "        if len(tensor.shape) == 2: # some images may be grayscale\n",
    "            tensor = tensor.unsqueeze(-1).expand(-1, -1, 3)\n",
    "\n",
    "        bitmap              = tensor.permute(2, 0, 1) / 255.\n",
    "        extensionless_fname = os.path.splitext(name)[0]\n",
    "\n",
    "        image = Image(bitmap, extensionless_fname)\n",
    "\n",
    "        if self.crop_size != (None, None):\n",
    "            image = image.resize_to(self.crop_size)\n",
    "\n",
    "        return image\n",
    "\n",
    "    @staticmethod\n",
    "    def collate_fn(images):\n",
    "        bitmaps = torch.stack([im.bitmap for im in images], dim=0)\n",
    "        \n",
    "        return bitmaps, images\n",
    "\n",
    "\n",
    "def extract(dataset, save_path):\n",
    "    dataloader = DataLoader(\n",
    "        dataset,\n",
    "        batch_size=1,\n",
    "        pin_memory=True,\n",
    "        collate_fn=dataset.collate_fn,\n",
    "        num_workers=4,\n",
    "    )\n",
    "\n",
    "    if args.mode == 'nms':\n",
    "        extract = partial(\n",
    "            model.features,\n",
    "            kind='nms',\n",
    "            window_size=args.window,\n",
    "            cutoff=0.,\n",
    "            n=args.n\n",
    "        )\n",
    "    else:\n",
    "        extract = partial(model.features, kind='rng')\n",
    "\n",
    "    os.makedirs(os.path.join(save_path), exist_ok=True)\n",
    "    keypoint_h5   = h5py.File(os.path.join(save_path, 'keypoints.h5'), 'w')\n",
    "    descriptor_h5 = h5py.File(os.path.join(save_path, 'descriptors.h5'), 'w')\n",
    "    if args.detection_scores:\n",
    "        score_h5 = h5py.File(os.path.join(save_path, 'scores.h5'), 'w')\n",
    "\n",
    "    pbar = tqdm(dataloader)\n",
    "    for bitmaps, images in pbar:\n",
    "        bitmaps = bitmaps.to(DEV, non_blocking=True)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            try:\n",
    "                batched_features = extract(bitmaps)\n",
    "            except RuntimeError as e:\n",
    "                if 'U-Net failed' in str(e):\n",
    "                    msg = ('Please use input size which is multiple of 16 (or '\n",
    "                           'adjust the --height and --width flags to let this '\n",
    "                           'script rescale it automatically). This is because '\n",
    "                           'we internally use a U-Net with 4 downsampling '\n",
    "                           'steps, each by a factor of 2, therefore 2^4=16.')\n",
    "\n",
    "                    raise RuntimeError(msg) from e\n",
    "                else:\n",
    "                    raise\n",
    "\n",
    "        for features, image in zip(batched_features.flat, images):\n",
    "            features = features.to(CPU)\n",
    "\n",
    "            kps_crop_space = features.kp.T\n",
    "            kps_img_space, mask = image.to_image_coord(kps_crop_space)\n",
    "\n",
    "            keypoints   = kps_img_space.numpy().T[mask]\n",
    "            descriptors = features.desc.numpy()[mask]\n",
    "            scores      = features.kp_logp.numpy()[mask]\n",
    "\n",
    "            order = np.argsort(scores)[::-1]\n",
    "\n",
    "            keypoints   = keypoints[order]\n",
    "            descriptors = descriptors[order]\n",
    "            scores      = scores[order]\n",
    "\n",
    "            assert descriptors.shape[1] == args.desc_dim\n",
    "            assert keypoints.shape[1] == 2\n",
    "\n",
    "            if args.f16:\n",
    "                descriptors = descriptors.astype(np.float16)\n",
    "\n",
    "            keypoint_h5.create_dataset(image.fname, data=keypoints)\n",
    "            descriptor_h5.create_dataset(image.fname, data=descriptors)\n",
    "\n",
    "            if args.detection_scores:\n",
    "                score_h5.create_dataset(image.fname, data=scores)\n",
    "\n",
    "            pbar.set_postfix(n=keypoints.shape[0])\n",
    "    \n",
    "    \n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\n",
    "    '--height', default=None, type=int,\n",
    "    help='rescaled height (px). If unspecified, image is not resized in height dimension'\n",
    ")\n",
    "parser.add_argument(\n",
    "    '--width', default=None, type=int,\n",
    "    help='rescaled width (px). If unspecified, image is not resized in width dimension'\n",
    ")\n",
    "parser.add_argument(\n",
    "    '--image-extension', default='jpg', type=str,\n",
    "    help='This script ill process all files which match `image-path/*.{--image-extension}`'\n",
    ")\n",
    "parser.add_argument(\n",
    "    '--f16', action='store_true',\n",
    "    help='Store descriptors in fp16 (half precision) format'\n",
    ")\n",
    "parser.add_argument('--window', type=int, default=5, help='NMS window size')\n",
    "parser.add_argument(\n",
    "    '--n', type=int, default=None,\n",
    "    help='Maximum number of features to extract. If unspecified, the number is not limited'\n",
    ")\n",
    "parser.add_argument(\n",
    "    '--desc-dim', type=int, default=128,\n",
    "    help='descriptor dimension. Needs to match the checkpoint value.'\n",
    ")\n",
    "parser.add_argument(\n",
    "    '--mode', choices=['nms', 'rng'], default='nms',\n",
    "    help=('Whether to extract features using the non-maxima suppresion mode or '\n",
    "          'through training-time grid sampling technique')\n",
    ")\n",
    "parser.add_argument(\n",
    "     '--model_path', type=str, default='/kaggle/input/imc2022-dependencies/pretrained/disk-depth.pth',\n",
    "    help=\"Path to the model's .pth save file\"\n",
    ")\n",
    "parser.add_argument('--detection-scores', action='store_true')\n",
    "\n",
    "\n",
    "# Hacky copy-paste: parameters go here.\n",
    "args = parser.parse_args('--n 1000 --window 9 --height 768 --width 1024 --image-extension png'.split())\n",
    "print(args)\n",
    "\n",
    "DEV = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "CPU = torch.device('cpu')\n",
    "state_dict = torch.load(args.model_path, map_location='cpu')\n",
    "\n",
    "# For compatibility with older model saves.\n",
    "if 'extractor' in state_dict:\n",
    "    weights = state_dict['extractor']\n",
    "elif 'disk' in state_dict:\n",
    "    weights = state_dict['disk']\n",
    "else:\n",
    "    raise KeyError('Incompatible weight file!')\n",
    "\n",
    "model = DISK(window=args.window, desc_dim=128)\n",
    "model.load_state_dict(weights)\n",
    "model = model.to(DEV)\n",
    "\n",
    "# Extract features for every image in every folder.\n",
    "for dataset_folder in glob('/kaggle/input/image-matching-challenge-2022/test_images/*'):\n",
    "    batch_id = dataset_folder.split('/')[-1]\n",
    "    print(f'Processing \"{dataset_folder}\"')\n",
    "    dataset = SceneDataset(dataset_folder, crop_size=(args.height, args.width))\n",
    "    described_samples = extract(dataset, f'features/{batch_id}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "216ab018",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-06T15:17:35.503990Z",
     "iopub.status.busy": "2022-05-06T15:17:35.503102Z",
     "iopub.status.idle": "2022-05-06T15:17:36.127896Z",
     "shell.execute_reply": "2022-05-06T15:17:36.127216Z",
     "shell.execute_reply.started": "2022-05-06T15:13:35.041578Z"
    },
    "papermill": {
     "duration": 0.695586,
     "end_time": "2022-05-06T15:17:36.128054",
     "exception": false,
     "start_time": "2022-05-06T15:17:35.432468",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "F_dict = {}\n",
    "for i, row in enumerate(test_samples):\n",
    "    sample_id, batch_id, image_1_id, image_2_id = row\n",
    "\n",
    "    with h5py.File(f'features/{batch_id}/keypoints.h5', 'r') as kp_dict, h5py.File(f'features/{batch_id}/descriptors.h5', 'r') as desc_dict:\n",
    "        # Compute matches.\n",
    "        dists, idxs = kornia_feature.match_snn(torch.from_numpy(desc_dict[image_1_id][()]), torch.from_numpy(desc_dict[image_2_id][()]), 0.9)\n",
    "        match_idxs = idxs.detach().cpu().numpy()\n",
    "\n",
    "      \n",
    "        if len(match_idxs) > 8:\n",
    "            F, inliers = pydegensac.findFundamentalMatrix(kp_dict[image_1_id][()][match_idxs[:, 0]],\n",
    "                                                kp_dict[image_2_id][()][match_idxs[:, 1]],\n",
    "                                                0.95,\n",
    "                                                0.99,\n",
    "                                                2000)\n",
    "        \n",
    "            inliers = inliers > 0\n",
    "            assert F.shape == (3, 3), 'Malformed F?'\n",
    "            F_dict[sample_id] = F\n",
    "        else:\n",
    "            F_dict[sample_id] = np.zeros((3, 3))\n",
    "            continue\n",
    "        gc.collect()\n",
    "\n",
    "        if dry_run:\n",
    "            image_1 = cv2.cvtColor(cv2.imread(f'{src}/test_images/{batch_id}/{image_1_id}.png'), cv2.COLOR_BGR2RGB)\n",
    "            image_2 = cv2.cvtColor(cv2.imread(f'{src}/test_images/{batch_id}/{image_2_id}.png'), cv2.COLOR_BGR2RGB)\n",
    "            matches_after_ransac = np.array([match for match, is_inlier in zip(match_idxs, inliers) if is_inlier])\n",
    "\n",
    "            im_inliers = DrawMatches(image_1, image_2, kp_dict[image_1_id][()], kp_dict[image_2_id][()], matches_after_ransac)\n",
    "            fig = plt.figure(figsize=(15, 15))\n",
    "            plt.title(f'{image_1_id}-{image_2_id}')\n",
    "            plt.imshow(im_inliers)\n",
    "            plt.axis('off')\n",
    "            plt.show()\n",
    "\n",
    "with open('submission.csv', 'w') as f:\n",
    "    f.write('sample_id,fundamental_matrix\\n')\n",
    "    for sample_id, F in F_dict.items():\n",
    "        f.write(f'{sample_id},{FlattenMatrix(F)}\\n')\n",
    "\n",
    "if dry_run:\n",
    "    !cat submission.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d3127e3",
   "metadata": {
    "papermill": {
     "duration": 0.033639,
     "end_time": "2022-05-06T15:17:36.198242",
     "exception": false,
     "start_time": "2022-05-06T15:17:36.164603",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 154.955883,
   "end_time": "2022-05-06T15:17:37.643266",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-05-06T15:15:02.687383",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
